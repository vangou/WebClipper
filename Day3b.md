# Day3b
关键词

大语言模型

知识图谱

问答机器人

指令微调

模型权重

聊天机器人

意图识别

数据库

模型结构

关系抽取

翠仪

00:06

在下午课程开始之前的话，我之前我之前对我们课程的一个内容做了一个简单的整理，然后这个这个思维导图可能有点大，就原图的话我也发到这个群里，大家可以这个打开群里那张图。糊了去给它放大去看。

翠仪

00:27

它实际上的话呢，呃，我们这个整一个垂直领域的一个问答机器人可以分成两条线，一个是基于这个现货量搜索结合到这个大语言模型的一个问答机器人。然后的话在上周的话呢，就蓝色，这里的话是我们上周已经讲过的内容了，就是它的一个数据形式的话，可能是这个问答对。然后的话呢，我们去通过对这个问题去进行这个emba的一个操作。存储到这个销售数据库里面，然后这个销量数据库的话，它文本内容呢是存储了这个问题和答案啊。这时候他如果啊，这个我去问问题了，然后的话呢，它就可以返回呢，就最相近的这个K个问题。比如说我设定的最相近的三个问题，然后呢，他会把这个呃，我们查询得到这三个问题，我们会把这查询得到的三个问题和他对应的答案，包括我们原先的问题呢，呃，一起输入到我们的这个。

翠仪

01:27

大语言模型中，然后要大语言模型去整合，生成最终的一个答案，那这是我们上周那个QA所做的一个事情，然后可能有同学问就是说，呃，为什么不讲那个最复杂的形式，其实它这个整体思路是一样的。包括，呃，这个你又不是LL它只是一个这个工具框架啊，这个对于我们解决这个问题的一个思路，都是没有任何的一个影响的。那我们再说最后的话，会给大家介绍一下lan这个框架。啊，因为它是一个很好用的工具，那当然就是说你在做自己的一个项目的时候，要不要用这个工具呢？是完全由你来决定的，你就是你平常你这个去做饭啊，你喜欢用大刀，可能觉得好。用一点，有些人可能喜欢用小刀啊，这个可能自己去写，把这个各个步骤自己实现啊，自己这个对这个流程清楚一点，然后对整个项目的一个可控性更强一些，都是可以的，就所有的这个工具。不过都是辅助我们去完成我们的一个项目，那对于这个实现项目的这个整体思路是没有任何的一个影响的。

翠仪

02:40

啊，所以这是上周的一个这个呃，基于问答对我们去得到的一个问题和答案，然后上周的话呢，因为我们的一个演示呢，主要还是在这个logo里面，然后其实我这个给你们代码呢，是有一个，呃。的一个版本，就服务器版本，那这个是用这个写的，然后这个暂时也开了这个对外的一个呃端口，大家也可以这个上去去测试一下，但是待会可能就关了，因为那个。呃服务器这个显存有限，开了这一个就加载不了另一个这个语言模型了，所以就只能是这个大家在这个呃，在我在讲到后面这个M二的之前的话，都可以去使用一下的。

翠仪

03:26

那就是这个问题，呃，问答对的这个上周所讲的为什么会用问答对呢？其实是因为问答对啊，这个问题和问题去比较的话，他们的一个呃去比较他们的一个的一个效果会更加好一些，毕竟。啊，两个问题之间比较相似度是ok的，但是你一个问题和一个这个文本啊，却比较相似度的话，这个逻辑上可能有点说不过去啊，这就不是不行，有一定道理，但是这个你说它效果一定很好嘛，呃，这个待会就。

翠仪

03:59

这就大家可以测试一下，就是在后面我们去实现用这个lantern这个工具呃，这个框架去实现这个对这个普通的一个长文本，比如说这个呃去做文的分块，然后再去做这个向量话术语的时候了。呃，它整个思路是一样，只不过是因为数据形式不一样，所以我们在做相当跨处理的时候，还有这个问题啊，这个输入的一个碰的时候可能是有点不一样。当然，如果你有其他的一些形式，就是以本地的一个数据库，它的形式可能不只是长为本的。你可能是其他的一些可能是视频呐，可能是图片，你可能还需要经过额外处理，比如说把这个图片里面的一个呃，文本给它转出来。视频呢首先要识别到它里面的一个呃，对话的一个内容就是。这个把视频里面的音频转成这个文本，再去做相应的一个呃处理也是ok的。

翠仪

04:56

然后的话呢，这个就是基于这个向量搜索的一个呃，结合到这个呃，大语言模型的一个问答机器人这条线的话，它其实是实现起来，它会非常，呃，相对的一个比较简单。落地化，因为你只需要啊，把整个模型框架搭起来，你只要把你的这个呃，本地知识库的一个数据啊，导进去啊，你就可以这个完全去实现了，呃，像一些比较简单的一个场景，比如说，呃，你想要做一个这个关于公司介绍的一个未来机器人。啊，可能有一些这个新创业的一个公司，然后他想这个呃，如果有人一直在咨询你们公司业务，你拼个人在这和找个机，这个机器人的话，成本就差很多了啊，那就是一个最成本最低。

翠仪

05:44

而且最好落地的一个方案。然后如果是基于这个知识图谱的一个未来机器人，是因为这个上面的一个方案没有办法满足你的一个使用场景的话呢，那你可以就是考虑更靠谱的一个知识图谱，因为知识图谱它本身这个构建的时候呢？呃，它就是会有一些这个比较。

翠仪

06:08

呃，复杂的一些工具，比如说像上周所讲的，一开始你需要这个把这个知识图谱。它整个这个实体啊，包含什么内容？呃，这个关系包含什么内容属性包含什么内容？最好是先设计出来先确定的，你要抽取怎样的一个实体？要抽取实体之间怎么样的一个关系，又去抽取某个类实体某些这个属性。那你设定的出来之后，你后面的一个路子才好走通，那这种的话其实往往需要非常多的一个业务经验，如果它不是一个这个可以有一个通用的一个方法论的一个东西啊，这其实，呃，跟这个业务经。呃更依赖于这个业务经验，就有些时候啊，这个有些客户他问我说啊，你建议这个实体应该怎么设计，那我这边对他的业务完全一窍不通的话，我是没有办法给任何建议。因为我只是一个呃，只能从一个通常通用的一个领域上面给它建议说通用领域上我们可能一般都是采这个呃这个什么机构名称啊，人物啊，这个时间啊等等这些关系，那就是如果。对你这个业务产品有一定的了解，我可能给你提出一个更具体的需求，但是呃，可能这个知识图谱设计方面的话，更依赖的是你的这个业务的一个经验。所以这里的呃，对于一些我不熟悉的一个领域范围的话，我也实在是没有办法去给出更多的一个建议，但是大家可以一起去探讨，就是，呃，你可以尝试给我讲解你的这个业务场景是什么样的，然后我再根据我的这个技术知识，再给你这个相应的一个建议。

翠仪

07:53

然后就是这个呃，图谱的一个设计部分，然后这个接下去的话有了这个设计，我们就是要按照我们设计去抽取我们的一个知识，那这个知识抽取的话，那你最这个简单的方法就是。人工标注啊，这个所有都是人工做啊，但是这个成本高，而且费时间，所以呢也有了一些这个监督学习，比如说人工先标注一部分成本，然后用这个呃，这个监督学习的框架，那监督学习框架的话。呃，在birth之前的话可能是这个呃双头的这个BI LSTM加上这个CIF这样的一个架构，呃，去进行这个抽取的。那有了boss之后的话，可能就是再加上一个呃，就是用but。取缔了这个双头LSTM的一个框架构，那它就是变成了一个P加这个，呃，CRF层。那它仍然还是一个这个监督学习的一个概念，就是它仍然需要有这个数据的一个标注。

翠仪

08:58

然后去训练这个呃，模型啊，虽然就是说这个知识抽取可能有很多开源的模型，但是这是开源模型针对的还是这个通用领域的，就是到了具体某个这个子领域上面的话，你可能你的实体。呃，就是跟别人的就是完全不一样，就可能一般人都想不到这是个实体，但是你不要把它定义为实情也是ok的。那这种的话，呃，在这种比较专，比较这个垂直的一个领域上面，这种通用的一个模型。这个开源的一个呃，这个它的一个预训练效果，你想去达到一个开箱即用的一个效果的话，基本上不行，所以基本上要走这个呃标注数据，然后去呃，训练这个知识抽取的一个模型，然后去获取新的一个知识。

翠仪

09:46

那这个DP一的话，双周已经讲了，我们会明天再去讲这个这这一个无间路学习方向，还有就是这个多种方法结合方向就无间路学习其实很好理解的，就是用大语言模型去帮我们去做知识抽取。那为什么又会有下面的那种方法，因为？呃，其实你明天可以对比一下各个模型，它的一个抽取的一个效果啊，你会发现GPG是啊，它抽取效果是最好的，但是它有一个问题是什么？GPG是会，而且第二个就是它没有办法去做一个本地化部署，毕竟这是。和闭源的一个东西，就是你没有办法去很好的去保证你的这个数据安全啊，就即使是open AI它这个保证说你的数据完全是加密的，我们是完全看不到的，但是这个它说是这么说，那实际怎么说呢？你也不知道说不定你的这个语料会成为GPT五的一个训练语料也不一定啊，所以说呃他可能人确实看不到，但机器全都看到了，那你呃，有些时候一些敏感数据你可能不想，他在GPT五那里就是跟大家都说这是。啊，所以说呢呃这。这种方式的话，不科学的话，那我们会有后面的这种就是呃，基于这个大云模型，它可能标注部分数据，然后我们再去做这个呃，监督学习的这个训练。

翠仪

11:15

然后知识图谱的一个构建的话，这个其实也没什么好说的。呃，比如说我们这个课上演示的这个六合这个图数据库怎么去这个导入这个节点，还有就是创建这个关系，呃，这个如果是其他图数据库的话，它其实。那过程也是类似的，只要我们有了数据之后，我们其他的都好做了，然后还有一些这个明天可能会讲到一些这个知识图，融合知识入的一些知识啊，那这个可能要看一下时间。

翠仪

11:47

然后这个问答机器人的话，这个基于上周所构建的一个简单的知识图谱的，我们也走了一个最简单的一个线，就是通过这个，呃问题模板，然后我们去进行通过这个条件去匹配啊，就是判断这个问题的类型。然后根据问题类型是生成这个查询语句，然后这个查询语句的套入到我的一个模板内，生成最终的一个答案。那这个过程的话呢，这也是一个相对来说最简单实现的一个方式。就比如说你的这个业务场景里面。它的这个呃它的问题就是可能这个客户对于呃需要问的问题，它本来就是比较简单，或者是你只是内部用的也不太追求这个呃问题，它这个呃包装的有多好。你只要知道我这个问个问题，它能快速给我一个答案就可以，那这种的话就是一个最方便，最简单的一个落地。那但是可能如果对外的话，这种这个最终的一个效果可能不够好，那我们后面呢，第二天呢，会讲到其他的一个方向。那就是我们这个呃。

翠仪

12:58

呃，垂直领域的这个问答机器人的一个两条线，一条是比较容易实现的，这个相当瘦手，另一条呢是结合到这个知识图谱啊，去加强这个呃，L YY M在回答的时候的一个答案准。学习那LYOM的话，这里呢也会有另外一条线，就是这个大语言模型，我们今天要讲的内容，一个是这个怎么去把这个大语言模型用的更好的一个碰的一个工程。第二个是说它的一个呃，我们呃会讲解一个大语言模型。本地化的一个版本，开源版本里面的一个经典代表就是啊，现在已经更新到第二代了，我们也可以去试用一下，然后还有就是它的一个微调，那到待会说到微调的时候我会跟大家说。为什么大语言模型还需要去这个进行这个微调训练，而不是说这个它能解决所有问题。然后还有就是基于这个lan的一个加工呢，我们会去再去把这个呃。常基于长文本这种语料的一个形式的一个问答机器人去实现，那后面的话呢？呃，其实这个大家如果学习的好用的好的话，它可以做更多的一个东西。呃，出来那就是大概的一个呃实验过程。呃的一个框架架构，那对于这一块的话，大家有没有什么问题，或者是说呃我这里呃这个讲的不够清楚的。

翠仪

14:40

没有同学提问，那我们就开始正正式开始今天的内容啊！就蓝色这部分其实都是我们上周讲过的东西，就是如果你觉得你看了这个思维导图，我觉得啊，有些东西好像我上周听了，但是你又好像没讲的话，那你也可以去问一下大家对一下这个内容。

田志军

15:01

诶，何老师。

翠仪

15:02

好好好你说。

田志军

15:04

啊，我有一个简单问题啊，就是你这个里面，呃，我们的知识图谱其实已经规定了它的实体，它的关系和属性了，那我们在做那个你下面在知识抽取的时候，它为什么要做人工智能标注这这类的？

田志军

15:19

它是起到一个什么样的作用啊？

翠仪

15:21

就说实体设计我只是设计了一个类型，比如说是公司这一类，那我不可能把所有的公司都列出来给他的呀。是不是。比如说我设计的是人民人物这一类，那这个人民上千上100万的这个就是它是无穷无尽的一个变化的。我不可能把语料中的一个人民权这个一下子都搜索出来的。我们这个设计设计的是这。有实体的一个类型，而不是说具体这个实体就叫什么什么公司啊，这个浩蓝公司，这个鹤影公司，方问公司不是的，我只是设置于它的一个类型，然后关包括这个关系设计也只是实体类型和实体类型之间，它可能存在的一些关系。那具体到某个节点啊，就比如说浩南公司跟鹤影公司他们之间有什么关系的话，我们还需要从原料里面去找出来。所以就是说，呃，它其实是存在一个早的过程，就前期只是一个概念的一个设计。

田志军

16:27

对，这个枣不就应该是那个？算法给我们找，按照我设计的实体以及。呃，他的关系给我找出来嘛，如果说我都是人工来去标注的话，那我还要还要这种算法干什么呢？

翠仪

16:42

所以这只是一个方案，就是这这是B型的，就是你可以用员工标注，比如说你举料非常少，我说不定你两天它就标注完了，那你还是那个模型干嘛呢？是不是。就是当你的语料非常多的时候，我们可能需要人工先去标注一小部分，然后再去训练我们的这个呃算法模型。

田志军

17:10

哦，您指的。

翠仪

17:10

这是这样的一个流程。

田志军

17:12

那那我我理解是不是说虽然我定义了他的实体以及他的关系，但是在实际操作过程当中，如果说我给他一些嗯标准的，就已经因为人标完之后就是确认的就是这样的，然后他再按照我这个案例加上我给他这个范式，然后在我的语料库再进行找。

田志军

17:29

哦，可能会呃准确率更高是这意思吗？

翠仪

17:34

呃，是的，但是它不是一个方式，但是其实它也是一个这个呃，NLP模型的一个推理过程，它会算它们之间的一个概率抽取概率。

翠仪

17:52

它不是一个显示的，就是说我什么条件我就能抽出来，它其实会基于这个呃，句，你输入句子的一个上下文去判断啊，某一段是不是我要找的这个实体，或者是说这个，这两个实体之间会不会存在矛盾？关系啊，是通过这样的一个抽取的，但这个具体的基础原理的话，你可以把它简单理解为可能，我就是有一套算法，我把语料塞给他，他就可以把我想要的这个实体关系属性都给它抽取出来，就是就是这样。

田志军

18:28

嗯，好，我没问题了。

lyonchen

18:30

诶，何老师。

翠仪

18:33

嗯，你说。

lyonchen

18:34

唉，我想问一下，就是现在因为从咱整个的路径来讲，制图谱和上面的向量，其实从您图上画的是两个分支。

lyonchen

18:42

是吧。

翠仪

18:43

嗯，对。

lyonchen

18:44

然后这两个分支是我们能变成。

lyonchen

18:47

其实不是说它是两个独立的，我必须要走一条线，或者必须要走向量，或者必须要走这个知识图谱，对吧，是可以融合在一起来做的。

翠仪

18:47

啊，不是你，你可以结合起来啊，就是你有些语料可能在像数据库里面，有些语料可能是在知识图谱里面都可以结合起来用的，只不过是这个从技术上我们可以这么分，那实实际的一个应用场景的话，你。

翠仪

19:11

很多人用这个方案你都可以综合起来一起去使用的。

lyonchen

19:16

对，那现在就是问题在于说。

lyonchen

19:18

我基于。

lyonchen

19:20

这个制图谱构建了一套我的制图谱的模型。

lyonchen

19:23

然后我向量里边呢，还有我向量里边的这个相关的呃，作为向量化以后的数据。

lyonchen

19:28

那真正一个问题下来以后。

lyonchen

19:31

我是从哪个方式走，还是两边两边一块儿查，查完结果给到LM里边儿去，然后再去让他去做。

lyonchen

19:39

这个问题啊，包括答案的这种。

翠仪

19:40

这个问题。

翠仪

19:42

呃，这个的话其实要结合结合到你这个业务场景，你的这个数据到底哪些是放在了哪？这个知识图谱哪些是放在了这个相关数据库？啊，就比如说他们可能是不同领域的话，那你可以先让这个大元模型去做一个初步的判断，这个问题啊，对它一个分类，它到底是属于这个，比如说，呃，像就是数据库可能是一些流程方向，它问的是一些这个规章制度。啊，这还是比如说这个知识图可能是一个金融知识图谱，它问的是一个金融领域的一个问题，那可能就去查知识图谱了。那如果，呃，这这是一种可能，第二种可能就是说你这个知识度也好，这个相当数据库也好，它是一个结合起来一起去使用的，它可能这个知识它就是在同一个领域上只是不同的一个表示，那你可以两个都查。把两个的一个内容都一起，呃，最后出到这个大语言模型里面，然后让他去最终整理出最终的一个答案就好了。

lyonchen

20:46

咱们现在的方问是怎么做的？

翠仪

20:47

呃方问呐，方问他这个。它的这个方法其实跟这种LOL还是就是这种未来机器人，它还是有点区别的。呃，它会更偏向于一个微调出来的一个子领域的一个模型。就是它的一个问题，失误，其实它是一个固定的一个指令，而不是说我是一个很发散的一个问题。

lyonchen

21:09

呃，方问没没用知识图谱是吗？

翠仪

21:18

因为它这个问题啊！有啊。

lyonchen

21:23

对，那现在等于是说那方便用了那个销量库了吗？

翠仪

21:24

啊方没用销量数据库，它方问是用这个大语言模型的一个微调，加上知识图谱。

lyonchen

21:36

行行，那我再想想啊，谢谢何老师！

翠仪

21:39

我我再想想啊，挺好的嗯！

田志军

21:42

诶，何老师，我有一个小问题。

翠仪

21:43

哦，你说。

田志军

21:46

就是我们那个方问它能够根据你的呃症状，然后判断你的疾病，然后根据疾病，然后再去进行出方。然后你是。那个根据这个疾病出这个方子，这个是怎么来去进行出出来的？还是用这个模板，这个疾病它就是这几个方，你给我随便拿出来一个还是说？

田志军

22:08

我是哦。用系统给它组一个方子出来的。

翠仪

22:13

呃，它这个开发的话AI开发它会。考虑到他的一个症状和他的一个我们诊断出来，在中医上叫做这个辩证，这症状和辩证一起去呃呃说到这个模型里面，然后让模型去给出这个开发的，并不是只靠他的一个辩证去开发的。

田志军

22:34

哦，对，就是这个模型是怎么给出来，我收集了我的症状啊，指指针时针。还有这种，然后他把他最后呃那些药物的这些属性，然后给给你一个方子出来这中间。呃，是怎么连接串联起的？没想明白。

翠仪

22:51

嗯，你说的是什么？跟什么串联没有听清楚。

田志军

22:55

好，你看啊呃中药医生的望闻问切就是呃肯定是问了你是什么的疾病，问了你的这些各种原因，然后判断你一个什么症，然后再根据他的这个理论，什么寒热虚实这些这些理论，然后再配上的。

田志军

23:10

一些药物的配伍，经济什么之类的，然后这样出的方子就是你的方位是怎么出，出了最后这个方子的？

翠仪

23:18

他问怎么去输出啊？那这个呃他他思考的原理呢？呃，我也不懂，就呃，就是因为这个模型它是一个理状态，它具体怎么这个是不是按照这个中医的流程上面去走的，我不知道。啊，但是这个我们这个现在开发的一个流程的话呢，是先根据他的一个输入的症状啊，我们先呃，给他去判断证，然后就结合到他判证之后啊，这个再加上他的一个。嗯，症状就有点像这个大于黏膜型，它是一个分布式思考的问题，它不是一蹴而就的，它其实是有一个过程，我们先考虑它的一个辩证，然后把辩证考虑出来了，然后再结合它这个辩证。还有我们有这些症状，我们。再去开这个AI开方，然后再基于这个AI开发我们这个给这个AI方去做一个方便，就解释它，我为什么要这么开，然后的话呢，最后再加上这，呃，再给出一个方剂加减啊，因为这个不同的一个人的体。是它可能在症状里面没有输入啊，就是不同人的体质，它可能需要对这个方去做一些的一个调整，然后我们再去给它做一个方进行加减的一个建议。

田志军

24:35

嗯，好的。

翠仪

24:36

是，是整一个流程化的一个思考。

田志军

24:38

嗯，好的，谢何老师！

lyonchen

24:49

诶，何老师何老师。

翠仪

24:51

哦，你说。

lyonchen

24:51

主要是再麻烦问一下啊，就是就跟还是咱这张图啊，就是咱们现在。

lyonchen

24:56

方问走的应该是就是下知识图谱的这个问答机器人。对吧。

翠仪

25:04

嗯，是，但你说他是一个问答机器人的话，他没有问答机器人那么的这个。

lyonchen

25:06

走下边就下去嗯！

翠仪

25:12

就是开放性没有那么强，因为他的收入只能是这个症状类的，那他说其他的话，我这边是没办法去进行这个回答的。

lyonchen

25:18

嗯嗯。明白明白，那现在就是走下边这条蓝线的时候。

lyonchen

25:26

蓝线下不是有两两个两条路嘛，一个是知识图谱构建，一个是问他机器人对吧？

lyonchen

25:32

那我们在这两条路，我们方问是走的哪条路啊？

翠仪

25:32

不是知识图谱构建和问答机器人，它不是两条路子，其实它是两个步骤，就是我前期要先建了一个知识图谱，然后我才能基于这个知识图谱去进行这个回答。

lyonchen

25:36

明白明白好，那就是这两条路，其实是我们需要做的两个步，两个步骤，对吧？

翠仪

25:49

对对对对。

lyonchen

25:55

然后呢，我们现在就是在我们做这个知识图谱构建的时候。

lyonchen

26:01

然后里边比如说我们知识图谱设计做了。对吧，知识抽取我们是怎么做的？这也是。

翠仪

26:08

就是抽取的话，这个就是。

lyonchen

26:10

也是人工标注吗？

翠仪

26:12

你你要看呃，人工标注就是要看你数据量啊，就是说以人工标注工作量为首的话，你肯定是最优的方案，就是人工标注了，是不是？那你这个。

lyonchen

26:22

不是我，我只是方问。帮问我们怎么做的？

翠仪

26:24

方方法是基于这个监督学习去做的，就人工标注的一部分，然后再去训练这个模型错误，得到最终的所有的一个标注数据，然后最后再做一个人工校对。

lyonchen

26:29

啊，建筑学习是？我主要是看咱实际是怎么做的，因为我们肯定是沿着实际的路再走嘛。好，谢谢何老师嗯！

翠仪

26:48

这个方问做的时候，这个大语言模型就是当时还没有出，不然的话可能人工标注都不用直接用大于模模型去做标注了。

lyonchen

26:50

啊，你就走那个那个？然后告诉他做知识抽取是吧？

翠仪

27:04

啊，对呀，就但但但是这个当时研发的时候还不是还没有出嘛，好几年前了，当时去做这个知识动作的时候，所以采用的是这个监督学习这个方案。

lyonchen

27:05

好，谢谢何老师！

王蓓

27:24

目前没有其他的同学举手提问。

翠仪

27:24

哦ok ok那我们正式开始到，进入到今天一个内容。就是呃，我们这个带语言模型的话，大家可以看一下这个这个呃语言模型的一个素，然后这边的话的粉质这一块的话是一个系列，就是其实这里不同颜色的话是按照这个。Former的一个，这块是一个encoder的一个呃模型的一个分支，然后蓝色这一块的话是decode的一个分支，然后中间绿色这一块的话是encode加decoder它都有的一个分支，那我们可以看到了这个。呃，这一块的话，它这个B出来了之后的话，基本上当时呢是以B系列为主的，因为它的这个效果确实是很好的，在当时呃说起来，呃，这个特别是你可以去用它的一个玉器粘模型。去结合到各种的一个下游任务的一个呃，这这个追加训练的话，你可以达到非常好的效果，就是在当时的这个呃。

翠仪

28:38

我们的这个decode模型是没有办法去做到的，因为decode它更在意它是一个深层式的模型，所以它这就说明了它的结果呢，其实是不可控的，所以就是一开始可以。大家如果有试用过GBT一或者GBT二。呃，甚至是GPT三呃GDP T三哦，我忘了它有没有开源。呃，但是有副线的一个模型，它这个效果都非常的一般啊，就是说因为我们在做一些精视这个特别的一些任务，比如说像秘密视频识别啊，这个关系抽取啊，这种非常精确的任务的时候。你用这个生成式模型，它可能没有达到办法去达到一个很好的效果，它会出现一个胡说八道的一个情况，那如果你是用这个系列去进行一个最佳训练的话，它往往可以得到一个比较好的一个效果。但是到。

翠仪

29:32

然后这个到了这个2021年，这一支好像就没有比较新的一个模型发展，因为它它已经到头了，各种基于B的一个模型，各种的优化，各种论文基本上能完了，都完了，但是可能还是说在很多方面他没有得到。这个呃很好的优化，那后面的话google就往这个呃整一个decode加一个方向去走，然后比较好的话，可能是这个T五呃T五在这里呢，又继续在晚上。整个这个有一个新的一个这个叫BT五，这个T五，然后还有就是这个呃一个比较呃最有名的一个模型就是C。就现在大家是会比较多人用的，然后这个这一块的话大家也看到了，就是这个GBT和GPT四啊，出来之后呢，效果确实是非常好的。呃，然后这里的话呢，这个不是实心的一个方，它都是一个必然的一个算法。然后像其他的这个出来之后的话，有其他的一些，像这个拉马模型啊，就也是比较多人用的，就还是也是一个decode的一个形式，那大家可以看到有很多这个，呃，学生领域。比如说像这个医疗领域啊，这个呃，法律领域的一些这个大语言模型，它其实都是在这个拉马的一个基础上呢，去进行这个，呃，指定微调的。那这是整个一个语言模型的一个发展体系，大家有空评评浙江湖的就呃，这个树的一个走向。

翠仪

31:15

然后的话呢，在这里给大家推荐一个这个项目啊，大家可以就是因为这个现在啊，这个语言模型发展的速度非常快，你可能就是隔几天又出来一个新的一个语言模型啊，你可以去呃。关注一下这个呃gp的一个项目，它其实是会定呃这个呃呃更新速度会比较快吧，它会更新一些，这个其实不仅仅是大语言模型，像这个比较旧一点的这个B系列模型，它有什么新的模型发布的话，它也。会根据呃更新在这个项目里面啊，大家可以去看到现在的一个大语言模型的话，呃，除了GLM之外，还有很多的这个，而且各个大学都在做自己的一个大语言模型啊，像这个你看。这个华东师范也说了，这个上海人工实验室也做了，然后还有就是这个呃这个这这种什么计算机大学的，然后它这是一个L YY M的一个模型，下面还有一个分类的话是LLY。就专门指他们有这个对话功能的，呃，这个刚刚所看到的这个书生图语啊，我是真的还没有用过，因为这个最新出的一些可能还是需要大家有一些这个使用的一个过程。

翠仪

32:37

去熟悉了解一下，它就要还呃，除了通用领域的话，它也有一些这个呃垂直领域，比如说针对医学的一个大语言模型。然后还有针对这个法律的啊，教育的啊，自媒体的都都有啊，大家啊，如果是有这种子领域的一个需求的话，也可以在上面去看一下有没有这个针对你想要做的那个领域里面。

翠仪

33:03

呃的一个香瓜的一个带语言模型。然后呃去看看这个效果怎么样？那这个现在是发展的非常的这个坏，这个呃GM二的话可能还是。呃就是各个模型，这个各个大学各这个机构都在发力，诶这个我可以预见的话，未来几年内可能会有更多呃这个不同领域上的一个呃语言模型给它出来。就可能就有人帮我们去做了前面那一步，那后面我们再去做自己的一个垂直领域的应用的时候呢，可能会更加的一个简单。那这个效果的话，大家就可以去呃，因为我没有办法去把所有的模型都测试一遍，然后大家可以去多看看这个里面的一个评论啊，或者是自己用的时候去对比一下。呃，其实很多这个。

翠仪

34:03

呃，这种语言模型，它的一个方案从这个可能都大差不差吧，就是跟那个B出来之后，有很多基于birth的一个微调。它可能就是跟可能差异不是很大，但可能是在一点的一个值方向上去做的一些优化，然后你可能是针对某一些特定一个方向上，它可能效果会比较好一些，那基于哪些会比较好的话呢？呃，就看。而且的话这个呃他们以这个模型的一个规模呢，也有大有小，就是像这个TUM它一直是UB的呃，它的一个效果。呃，其实你说它很好嘛，也说不上，因为它确实跟其他的。规模更大的一个，比起来的话效果非常一呃，非常一般，但是它是在小巧。就就大家可以按自己的需求去选择就呃，简单的一个方向的话，它呃，大一点的话，它效果普遍会好一点，那你说好好是不是能好到它的一个成一个线性关系的，比如说30。一是不是这个61的一个五位呢？这也不一定说得上啊，这个我也没事试过，那这种可能就只能是靠大家多去测试一下，看看这个效果。

翠仪

35:25

然后还有一些这个语言模型的话，它可能是在这个除了transformers就是上周总给大家在上面的一个呃，社区里面的话，还国内的话，这个埃里的一个达摩院呢，也有做一个这个。开源的一个社区叫做这个呃，models go，但是这个呃里面的一个模型大部分都是由达摩院去贡献的，就呃，有点像这个阿里这个达摩院它本身所为了这个。放自己的模型所构建出来一个社区啊，但是它里边的一个中文模型呢，相对来说呢，会比较多一些，然后有很多这个阿里他自己做的达摩院自己做的一个模型呢，也在上面，他可能，呃，这个在上面找的话可能会更。好，去找到它相应的一个模型。那这是一个社区的一个介绍，那大家这个模型的话，要不就是在这个呃店铺上面找，要不就是在这个呃上面找，要不就是在这个达摩院这个呃摩塔社区上面去找啊，这都可以。

翠仪

36:36

那就是这个大语言模型的一个发展的一个创新啊，大家可以看到这个语言模型现在就是发展是这，这特别是这个最近几个月啊，越来越多了啊，但大家不知道之前用这个或者就是说用其他的语言模型。会发现他有时候会显得比较少。其实是因为啊，可能是我们问题的问题不够好，所以也针对这种太原模型呢，也提出了一个叫做power engineer，就是这个工程提示工程。它是一个很很新的一个学科，毕竟就是出来之后它才能提起的，把它这个作为一个学科啊。但事实上的话，它，你说它这个呃，学科好像也说不上它的一个理论的话也是就是那么。啊，所以大家可以去先去了解一下它的一个情况，就是你掌握的越多，这个pop的一个技巧，或者是说你能找到一个比较好的一个P，在你的一个利用领域。里面的话，那你可以做的事情呢就会呃，可以把这个问题啊，就是做的更好。就一般用户输入的它可能是单一个问题，但是如果，呃，你把这个用户的一个问题结合到你自己的一个P，比如说，呃，给这个代语言模型去指定它的一个角色啊，去指定它的一个输出的一个，呃，结构。那我们可以获获得更精准的一个答案，而不是说这个呃，随便他这这个随便跟你说一些这个很很这个一本正经的一个胡说八道，看上去很有道理，仔细，真的经不起推销的。

翠仪

38:21

那只要说一说这个P用的好的话，呃，这个语言模型呢，它还是可以在一定程度上可以帮助到我们在这个去做自己项目，或者是在工作上去做，那这个大家去测试的时候，也可以去直接用这个钉钉上面的一个资源。去测试啊，我这个个人也是呃，时不时就是这么去测试各种的一个。然后的话呢，这个这个P其实它这个提示词的话，它可以包含这些要素，大家可能就没有很认真的去考虑过它其实第一个是包含它的几例，就主要是说你这个模型它要做的一些特定的任务啊，或者是说它要做一。一个什么样的一个角色，而不是说你要呃，让他翻译的话，你是可能第一句话就是跟他说，请将我把这句话翻译成英文，这是一个这个指令呢。然后或者是说你是一个什么什么的一个工具啊，呃，需要做什么，这些内容都是它指令，然后才到我们具体的一个输入的一个上下文。啊，这个或者是输入的一个信息，还有这个上下文，然后输入的格式的话，同样的我们也可以在这个泡沫里面一起去提醒，因为有些时候如果你不给它指定这个输出的话，呃，你很有可能得到的一些就是它都是输出一个文本。

翠仪

39:46

你如果想要一些比较精确的一个的回复的话呢，可能就很难去解析到，就是你人可以看明白，就比如说我让他去做这个秘密实体的一个标注，然后他回了一段话啊，我从这段话里面找出了这个秘密实体。呃，这个可能以下实体就什么什么公司什么什么，那你还要对他这段话去进行解析，那就很。

翠仪

40:11

很很很很多此一举，所以一般在做这种这个特定任务的时候，我们会尽可能的让它规范它的一个输出，然后我们可以直接来到输出，再去做进一步的一个加工的一个工作。那就是最好的。那它这个这里呢也介绍了，就是说我们在去做pm的时候呢，我们可以从简。很难的开始，然后的话呢，呃，让他觉你觉得它效果不满意的话，再逐渐的把你的一个P呢呃再去进行这个优化，就这是一个通常我们去找一个合适的一呢的一个。

翠仪

40:51

迭代的一个过程。就我们呃尽量呢在这个指令的上面呢，用的语言呢是比较简洁而有效的，而不是说你要把它巴拉巴拉的这个说一大堆，呃，就这个指令的时候尽量呢是比较简洁。也有呃，这他这样的一个输出呢，会相对来说会比较有效一些。然后还有就是具体性的话，就是肯定是越具体越好的，然后呃可能还得需要考虑到这个长度限制，因为所有的一个输入我们都有这个就收费，然后这个to肯定有上线，所以也需要考虑到。

翠仪

41:35

怎么简洁和具体的描述到你的这个具体的一个需求？然后就是避免一些模糊化的一些呃概念。然后呢还有就是说一些这个呃，有一些是让他不要去做什么，不要去做什么，就是呃这个心理学上也有一个这个我忘了叫什么名词，就是说你越强调某一个人不要去做什么，他可能把记住了这个。比如说你要呃呃某个同事去给你买一束红色的花，然后如果不断的给他强调说不要买蓝色的，不要买蓝色的，不要买蓝色的，他有可能最后给你买了一。一个蓝色的话，所以就是我们要把这个注意力呢放到这个具体要做什么，只关注具体做什么，不要告诉他不要做什么啊，这这种的话呢，可能会更加有效。

翠仪

42:30

然后这个P的一个工程技巧的话，其实呃，更多的是需要自己在跟这个语言模型去沟通的时候，呃，去实际去体验的一个呃，情况，那这里的话也给了一些链接给大家去。这个参考它也有一些这个里面也有一些这个P的一个样例，就比如说你在不同的场景下啊，怎么去写这个P呢？可能会更加好，然后你也可以根据实际的一个需求的去修改这个P，那这是一个这个P的需求。

翠仪

43:02

那么这个矿工程的话，其实是贯彻到整一个待遇模型的各方面的一个应用里面的啊，包括后面啊，这个跟他去做这个呃，基于相关搜索的一个呃知识问答机器人的话，你也要设计一个这个合理的一泡。啊，包括这个后面我们再去做这个知识图谱的时候，你的一个输入啊，怎么去让它输出，也是需要设计一个合理的一个炮啊，这个更需要结合到你具体的业务场景去设计啊，并不是说我这里。

翠仪

43:35

我这个课上给你提供的一定是最好的，最准确的啊，没有什么没有什么都是一定是最好的。就这种就是靠实践出真知了。就只能说给你一个参考。呃，这个你在实测过程中可能是对我用的一个碰，可能对于你的这个领域上来说，它这个效果就是一般，那可能你就需要，呃，去进行一些修改了。

翠仪

44:04

呃，那就是一个胖的一个使用，呃，这个就就倒也没有太多的需要去说的，那大家呃有需要的话继续去看就好了。呃，然后下面呢，我们来看一下这个M二。那GM二这里指的是六B模型，然后它上一代叫CG啊！牛逼，那其实大家不知道知不知道这个有一个13B的一个版本，但是是内测中的，然后我以为它会先开源一个13B的一个版本啊，没想到它这个直接这个。开源的这个M二，然后这个13B的一个版本目前还在内测中，大家有兴趣的话可以去注册一个账号，但是它不是呃他他没有开源，它只是一个聊天的一个界面。呃，但个人使用下来的话。它会比这个CM六比强一点。那跟CTO MO的一个比较的话呢，可能有一些场景会比这个CDO M要好一些，但有一些场景跟这个CM呢，又比它好一些。所以这个。谁好谁不好的话，也不能一概而论，还是要看剧的一个场景。然后的话呢，它在这个第一代的一个功能上面呢，它做了这个更多的一个数据的一个预训练啊，所以它的一个，呃，效果呢，有了更好的一个提升。第二个就是说它把这个上下文。

翠仪

45:40

那一个长度呢？再扩展呢？呃，所以呢，它可能就是说，呃，这个对话的一个轮次可以更多了，然后呃可以说的一个内容呢也更多了，然后它这个推理的一个速度呢，也这个得到了很好的一个提升。呃，然后这个显存那个占用呢，就是降低了一些。但这个量化下的话，它就可以就是有支持更多的一个对话的一个长度，就用这个it是量化的话，大家也可以在一个呃比较普通的一个笔记本电脑上面，只要六G的页前存的话，你也可以去刨起这个。就是需要更低的一个硬件资源，而且更高的一个推理速度。

翠仪

46:29

然后这个开放协议的话，这个它在这个商用这里的话呢，呃，就是说呃。嗯，你对他这个说明一下，就获取到他这个书面许许可之后呢，你就可以经过这个商用了。那这这这这是一个呃更换开放的协议也好，或者是什么样也好，就呃其实他也没有办法去管住你到底有没有用他的一个模型？然后就是他的一个主页去啊，呃做的一个溜冰。

田志军

47:14

何老师。

翠仪

47:14

那它上面的话呢，其实这个具体的一个指导的话还是写的挺详细的。就，呃，如果你单单只是想用它的模型，而没有说其他的一个需求的话，那这个模型直接用这个transformers这个包就可以了，就把模型权重加的呃，这个下载进来。然后就是可以直接去调用，这如果仅仅是在调用上面，那如果你是想把它做成一个这个web端的一个应用或者是API的应用的话，你就可以去看一下这个T GLM二它的一个gif的一个官方说明。有就是它的一个这个评测的一个结果。然后的话，它的一个使用方式呢，也是非常的一个简单啊，本地加载模型的话就是基于这个的一个transformance的一个包，只要这个更新模型就好了。

翠仪

48:11

然后就是提示一下大家，因为这个M二呢，它还在一个不断的一个迭代更新中，所以它的一个模型权重和它的一个项目文件呢，可能，呃，你隔一段时间不看的话，就可能就它更新了啊，如果你在跑代码的时候呢。呃，出现一些很莫名其妙的一个错误，就比如说模型某个成长不到啊，这个加载这个对不上啊，等等的这些就是跟这个模型推理的时候或加载的时候有问题的一些情况，想请先更新一下这。

翠仪

48:44

的呃模型权重啊，你去看到它模型权重的一个页面的话，可能会看到啊，它前几天又更新了一些内容。那么这个的话，这周版本跟上一周的一个版本相比呢，它确实更新了一些内容。呃，好像是更新的一些配置，然后还有就是token上的一个内容，这个模型的一个呃，权重倒是还没有更新，所以大家可以去看一下自己下的一个版本啊，是不是一个最新的一个版本，不然的话可能会出现一些奇怪的一个错误。

翠仪

49:20

然后它的一个使用的话，就是你要去做部署的话，使用也很简单，你首先呢，用一个把这个项目下载下来啊，如果是这个直接有呃，安装到的话呢，那我们就直接在你相应的一个目录下面去下载下来，拉取下来又好。那如果你没有装这个get工具的话，你可以直接在这里扣，点击下载这个J IP的一个压缩文件，然后把它解压到你想要的一个目录下面也是ok的，然后它会有一些这个依赖安装的一个要求。

翠仪

49:54

那大家呢？呃，我这里呢预先已经下载到了，它就是在。呃，这个目录下面就是GOM的一个六B上面。这个大家可以看一下它的一个目录结构，嗯，然后的话呢，它需要我们在这里呢去安装一下。它的一个要求的一个配置文件，那建议呢，大家去改一下它这个配置文件里面的一个内容。因为呢，它配置文件呢，要求的是那个。就是它的一个touch版本呢，是要大于等于2.0的。那我实测的话，因为我之前给它的绩效也好，或者是心理环境也好，都没有用到这个touch2.0的一个版本。呃，所以大家可以把这一行呢给注释掉，那它就不会下载一个2.0的版本。那实际上在这个touch这个一点几的一个版本的话呢，它都是可以使用的啊，就是呃，实测或是可以用的。当它这个官方说的话，你用2.0这个版本的话，它的一个推理性能会更加好，因为应该就是它有这种大版本的一个迭代的性的话，应该它是对它的一个推理上面去做了更好的一个优化。

翠仪

51:23

H GLM二呢也基于这个呃touch的一个2.0的一个版本去开发的，所以它应该是可以更好的呃，适配这种优化，那大家可以按需去进行这个安装，如果你本身这个环境用的就是touch二点。你以上的版本的话，那你就可以装2.0的一个以上的一个版本。那这是要注意的地方，就是要把它的一个这个里面的一个呃，这一行给它注释掉。然后我们就直接运行这一行命令的话，就可以去进行安装了，那我之前已经安装过了，那如果大家没有安装的话，呃，又想部署一套这个二V的话呢，也可以，就是按照我们刚才所说的一个步骤先。呃，给坑了下来之后进入到这个目录，呃，这个，然后安装一下我们所需要的一个包。然后把呃安装之前的话，这个把这一行注释掉就可以了。

翠仪

52:28

然后transformers的这个版本的话呢？呃，不一定要这个更新的一个版本，如果你是这个之前给大家好像是，然后6.1的话也是OK没问题的啊。但如果这个建议的话，还是更新到这个版本，就是新的，可以建用旧的，但是旧的不一定是人，这个有新的一些功能。然后它的一个部署方式的话，它提供了一个非常简单的一个脚本呢，可以帮我们去呃，非常快速的去部署一个类似这样的一个聊天的一个网页。那刚刚的这个我要先把它关了，不转这个。这个没办法去使用。呃，所以在这里的话呢，我们也可以。就是在这个T GM26B的时候呢，呃，我们也可以去按照它官方的说明，去部署这样的一个演示应用。那你在这里呢，可以做一些修改，比如说你这个可能不叫它演示，叫其他名字也可以，然后需要修改一下的是这个wet demo里面的一个。呃，模型权重的一个加载路径，它默认的话呢，是这个上面的一个下载一个路径，然后如果大家已经下载好这个全程文件到本地目录上面的话，修改一下这个。呃，权重文件的一个目录啊，避免重复加载或者是说为了这个避免。这个下载太慢，然后启动失败。啊，就是这里呢要呃这个修改一下。

翠仪

54:11

然后的话它它运行的话呢是？呃，通过这样的一个方式，然后它在运行之前，因为这个web端的话，它是用的这个steam这个框架。所以的话呢，但是它那个requirements里面又没有写这两个框架，所以你你也需要安装一下这两个包。嗯，大家这个方便的话可以跟我一起去操作啊，当然这个我已经是安装好的，就是这两个，不然的话你在运行这个代码的时候它就会报错。

翠仪

54:53

然后的话，这是一个这个运行代码的一个命令，它不是用python去选择它是这个CD啊。这个包的话就相当于这个flask的一个包，但是可能它用的一个技术呢，可能会比flask更新。然后后期的话，你这个更新年代的话，后面就不用发，可用这个呃这个写API这个包了。然后它就是这个论这个我们的一个P脚本，然后在这里的话，我们可以设定这个，呃，服务器的一个端口，那这要看你的服务器呢，有没有去开通这个官网的一个端口。那这个如果像驱动云的话，因为还没有签这个。公开专属的协议的话，所以就外网是掌握不了的呃。呃，像这个auto dial的话，它是开了这个666006这个端口，但是它开了一个，就如果你有更多的一个应用需求的话，建议你用其它的一个服务器，可以把它部署到不同的一个端口上面。

翠仪

55:57

啊，去进行这个使用？要买多大的鞋？嗯，这个十三，十三玉吧，就大概是十对对对对。呃30904090都可以用。它大概占的显存，现在加载下来的话就是。呃，刚刚可能从关了，大概是13天左右，我之前看的时候。因为他问问题了，才加载那个，大家也可以回到刚刚的那个页面里面。就可以更新一下，那就是一个这个T GLM二的一个演示了。但是他。嗯。不是改了什么吗？

翠仪

57:05

我把他这个不小心把他参数给删了。我重新启动一下。

翠仪

57:22

然后他在问问题的时候才会去加载这个模型的，所以第一个问题通常会比较慢一些。然后他会显示他正在思考，然后就是出现这个回复的答案，但我觉得这个界面上来说可能使用感不一定很好，但是这个你要用的话，你肯定需要对他页面去进行进一步的一个修改。

翠仪

57:50

那这个修改是怎么样的话，就是看你们的一个应用程序的一个需求了，因为大家这个不同的一些呃，项目，而它可能有不同的展示需求，比如说你可能不想要这边的一个设置啊，你可能只要一个这个。呃，聊天的界面或者是说你就聊天界面需要嵌入到别的一个页面里面，那具体这个前端页面怎么设计的话，就不是在我们这个课程的一个核心内容里面，那这个肯定是偏向于这个前端页面的一个设计，这个前端怎么写的？啊，所以就啊也不要问我说老师，我想改这个前端怎么改，呃，这个前端不是我这个技术方向，呃，我这边一般都是给公司的前端图式去实现的啊，我这个我们只负责最核心的部分算法的这个。呃，核心部分给它搞好就行了。

翠仪

58:43

那这是它的一个web端，呃，它的一个使用也是非常的简单，而且它也是有带这个对话的，这个左边这块的话可以去显示，呃，去设定一个这个M二的一个参数。然后大家也可以去试用一下。这个呃，这个感受一下TOM二的一个效果，当然这个钉钉机器人上面的一个TOM的话，它也更新成这个TOM二的一个机器人，大家如果觉得在这一些这个麻烦的话，也会在钉钉上去进行这个测试。

翠仪

59:20

那这是它的一个这个web服务啊，大概是这样子的。那它也可以去，呃，在这个对话框里面就是这个终端里面去使用。就如果你的服务器可能没有这个呃，可视化界面，但是你又想是使用的话，你。用这个呃CLI的一个工具，它就是这个运行一下这个命令就好了，在命令行里面啊，用，或者是说你这个服务可能只要给他给到他其他的一个前端服务一个API端口。

翠仪

59:51

啊，就行的话，那你可以直接去运行它里面的一个API的一个拍成文件，那它会自动的去呃，构建一个这个API端口。然后你可以就如果你这个端口的一个呃路径需要改变啊，或者是做一些这。这个呃，这这因为是已经做了一个这个全网的，就是只要你能访问到这台机的话，这个88000的一个端口啊，它都会访问，那有些时候可能是端口的限制，你可以改一下它的端口。在它的一个呃模型文件，呃，就是这个API的一个文件里面。就在这里呢，去改它的一个端口，就因为很多时候8000不已经开通了80端口，你可能改成其他的一个端口都行。然后同样的，无论你运行哪一个脚本。你需要先修改一下脚本里面它写的一个默认的一个呃，这个模型的一个路径，当然如果你用多显卡的话，也可以去把这它下面的这些给它注释掉，因为它也支持多显卡的。一个呃使用。

翠仪

01:01:13

那就是这个COM二的一个部署这一块，那呃，包括这个刚刚所讲到一个碰的一个工程，是大家对于这一块有没什么问题？它主要增强。

翠仪

01:01:35

它主要跟比差在哪里？首先。就是他看起来就不像一个人的，他像一个人，但是他回答的就不一定是你想要的。对，我问一下，不会也不会。我是吧，就只能说有一..对，问他19加19。这个这个可以算的呀！正常的情况下，像这种包括他的，他的你都都送到这种。这种简单的问题他肯定是可以回出来的，他可以解答19加十等于29啊！它就可以出来了。他还是，但他的那个能力确实比不上这个GPT，你想想他才六B的一个参数量GPT多少参数量，如果他比得上的话，就不用开了。它可以。就是他可以自己去计算，他知道这是个公式是吧？嗯，我觉得就其实他非常多，但是你想过一点这个。

lyonchen

01:03:07

呃，何老师。

翠仪

01:03:07

哦，你说。

lyonchen

01:03:10

呃，那个什么就是刚我听到现场在问说六。他的这个问题在哪儿跟？那个G PR是吧，因为我我装完了这个。然后我试了一下咱们上节课的问题，就是王一是王二的父亲。王二是王三的父亲。王一跟王三之间什么关系？

lyonchen

01:03:27

六逼回答出来的这个结果是兄弟。

翠仪

01:03:28

那那他就是没有办法去做这样的一个推理，他会做的是兄弟啊！

lyonchen

01:03:34

对它的推理。对对对，你可以，王老师可以现场可以试一下，我完我装完测完以后就是兄弟。然后所以他推理其实是很差的。

翠仪

01:03:48

嗯，确实这个。现在推理上来说最强的还是这个GPD。

lyonchen

01:03:55

啊对对对，然后这第四我试了，然后他们回答的是准确的。

lyonchen

01:03:59

啊，是他的爷爷啊！

翠仪

01:04:07

我不是三。就是它在使用上的话，呃，可能需要更多的一个引导。

lyonchen

01:04:26

对吧，这个当结果是一样的。

翠仪

01:04:28

网络是网上的兄弟，你那个一个同学在家里？

翠仪

01:04:32

那是不好意思。

lyonchen

01:04:34

对，王老师，我何老师，我有个问题啊！

翠仪

01:04:37

嗯，你说。

lyonchen

01:04:37

就是想问，就因为我们现在想搭一个私有化的一个，这个就是咱们所。所说的垂直领域的一个嗯，大模型的一个平台吧。那就是，那我们现在比如私有化部署，我现在比如说需要多少台服务器，然后咱们有一个。

lyonchen

01:04:53

大概的一个。配置的范围嘛，有多少台服务器以每台服务器的配置？

翠仪

01:04:56

那个不好意思，刚刚有一点没听清楚，你是想是有化部署这个是吧，对这个硬件资源是？

lyonchen

01:05:05

对对对。对对。

翠仪

01:05:09

呃，这个其实它单11个模型的话，它大概就是一个要需要13G左右的一个显存，你可能这个预留到这个呃。

lyonchen

01:05:10

你有什么建议吗？

翠仪

01:05:21

20G啊，就就可能有一些这个推理啊，包括它后面可能越来越强。这个对话的一个呢，是它还可能会有一些这个显得的一个占用，就一般现在这个，比如说像我这个部署的一个呃，环境的话，是一个3090的一个显卡，它也是能固起来的。

lyonchen

01:05:42

呃，您是等于单台机器吗？就是比如说我们现在做一个等于做一个科研平台吧。

翠仪

01:05:48

嗯。

lyonchen

01:05:48

单台就跑起来了吗？还是说我们需要比如说。三台，四台，五台。

翠仪

01:05:53

呃，这个要看你们的这个业务的一个并发量。

lyonchen

01:05:59

对，假如说100并发的这种，咱们有什么建议吗？现在是？

翠仪

01:06:03

呃100并发的话这个。你别照顾自己，因为他一般会需要排队，而且他本身推理也需要一定的一个时间。呃，可能去做这个三。333套左右的一个并发就好了。

lyonchen

01:06:23

呃，那就是三台3090的福气是吗？

翠仪

01:06:27

哦，对。

lyonchen

01:06:30

那对GPU没什么要求，是不是对CPU没什么要求是吧？

翠仪

01:06:35

CPU的话就一般你这个现在。CPU都不会太差吧，就其实它是一个配套的。这个硬件配置的话，可能呃，这个你可以跟这种硬件东西稍微去确认一下，因为你可能你用上了3090或者是090你这个总不可能用个I三I五之类的这个。

lyonchen

01:06:59

哦对对对对！

翠仪

01:07:00

呃CPU吧。

lyonchen

01:07:01

对，我知道，就说像这种C。

翠仪

01:07:03

就是它的一个CPU占用率倒不是很高，你看一下现在在用的时候它这个CPU使用率。呃，基本上是非常低的一个状态的。它峰值可能就呃就可能是呃，但是这个CPU的话它可能效果会这个比较好一些，就这个要看呃它它是一个整体的一个配置，但但在这方面这个确实。

lyonchen

01:07:30

明白明白。

翠仪

01:07:32

是很专业。

lyonchen

01:07:33

没事，我就我就咨询一下。然后呢，那个内存一般也就是180。一种。

翠仪

01:07:39

嗯，差不多差不多。

lyonchen

01:07:41

啊，我看您这写的80嘛是吧？

翠仪

01:07:43

啊，这是它的一个服务器的一个标配，那你这个内存的话其实用的没有那么多。

翠仪

01:07:50

呃，可能十来20去就够了。

翠仪

01:07:54

就就在实际使用的话，当然你还有你服务器可能有别的一些用户需求，你可以预留多一些这个呃内存，比如说就留到24级。

lyonchen

01:07:59

对对对。啊，主要就是其实gpu的资源是吧，就3090然后三台。然后100并发就可以了是吧？

翠仪

01:08:12

嗯，对。

lyonchen

01:08:13

好嘞好嘞，谢谢何老师！

许涛

01:08:19

何老师那个？

许涛

01:08:24

就是那个在git hub上你说的那个就是chat GM六B它这个。

翠仪

01:08:24

你说。

许涛

01:08:30

嗯，里边有一个有有一个那个就是什么啊，稍等就PP turning的里边那那些一堆的那个PY的文件。

许涛

01:08:40

那就那对源代码是是指是一些什么样的源代码，因为我我也没读过他们这些东西。

翠仪

01:08:45

嗯，对面待会会讲是一个这个微调的一个代码。

许涛

01:08:51

哦，就就就就是是下游任务用的一些东西是吧，我看还有好几千行代码那个。

翠仪

01:08:57

嗯，对，后面后这个下面就马上要讲了，但是我们可能先来个课间休息看一下大家有没有什么问题。就没有问题的话，我们先课间休息一下。

许涛

01:09:05

然后这不是？呵呵。所所以所以我就想问问，再问下一个问题，就是呃就是这个，它就比如说就说这个GM LG RM这个。呃，其实它没有什么源代码是吧，它开源也也就是开就是开源这个模型没有什么源代码开源的是吧？

翠仪

01:09:21

呃，没什么，就是模型结构上面，你也可以在它这个模型权重里面去看到的，所以这个呃，它整个模型相当于非常公开，就包括它一个呃模型结构，整个模型这个各个节点的一个权重也都拿到了。

许涛

01:09:38

哦，就是还那就还是开家的。

翠仪

01:09:39

我就可能就是他没有开始，就是他训练过程的一个代码。

许涛

01:09:44

啊，对，我就说他那个训练过程的那个就是。

许涛

01:09:47

他那个那就是一个他那个本身构建的这个代码还有。

翠仪

01:09:49

呃，其实它这个GLF二它是有在这个微调的时候，有一个全量参数的一个微调的一个脚本啊，你可以通过那里去做一个整，就相当于一个这个预训练的一个最佳训练吧。用自己的数据，当你有这么大的一个数据量的时候。

许涛

01:10:09

他这个模型构就是构建出来之前的时候就是他，他那个本身，他们之前的那一堆代码，没有什么开源的，什么就是。就是他这个源代码，他肯定是也是训练出来的嘛，就是他那个训练的那一堆代码，比如他肯定是个transform怎么写的，还是怎么着的，就就那些东西。

翠仪

01:10:28

呃，它训练的一个代码其实就就就就就没什么，就需要开不开源的，它整个模型结构是固定的。

许涛

01:10:38

就说到底它就是个transformer呗，是吧，也就是只要能，能不能把那个transformer那些源代码看了，就就基本上就代表它的一个一个源代码了，是不是？

翠仪

01:10:46

对呀对呀对呀！

许涛

01:10:50

哦，那那我理解的话，那那他们这个和这各种大模型之间，他们那个区别是不是也除除除了这个数据量这个这个差别之外，也没有什么太大其他的差别了，从原代码上是不是？

翠仪

01:11:04

嗯，预训练的一个数据可能会有一些不一样。就很多模型的一个区别是区别在于它的预训练的一个数据不一样，就像这个基于拉马做了很多模型，但它的一个模型基座都是拉马，只是预训练的数据不一样，然后就衍生了很多不同的。

许涛

01:11:28

呃，就上上午不是那个黄老师讲的一个问题就是。呃，那个GPT还有那个就是那个不是呃它有JPT用的是那个就是它它是呃是一个语言模型，然后。

许涛

01:11:43

遮住后边，然后从从前边猜后边嘛，然后那个B不是从里边去掉几个单词去猜给他做什么，完形填空就这种。这种这种逻辑。是有有有这方面源代码吗？就是。

翠仪

01:12:02

你说的是transformer transformer的源代码还是说？

许涛

01:12:07

其实这个也就是穿方面源代码是吧，可以理解的是或者叫不二的源代码或者GPT的源代码。

翠仪

01:12:10

呃，高层的元代码，你一收就是这个，这个项目都是开源的，谷歌也开源了他的元旦嘛，包括这个呃预训练的一个过程。就是你你要呃，如果愿意的话，你有这么大量的数据，你也可以去重新训练，从零开始训练一个不同的一个模型。

许涛

01:12:30

啊，对，我就说就是想，哪怕从学习的角度就是想。自己能不能类似于这种，它是叫六B，哪怕是学那个66兆的或者什么类似于这么这么一个过程跑下来这么一个一个过程，就是有没有这样的东西可以可以可以做的。

翠仪

01:12:46

呃，可以做，就是你要从零开始训练一个代语言模型是完全行得通的，就除了这个COM啊，或者你要复现一个CG PT的话，也有一个开源的框架啊。不过这个在我们上一期的课程上面有讲过。然后这一次的话可能就是跟这个未来机器人不太相关，所以我就没有讲到这里。

翠仪

01:13:08

那部分的一个内容了？

许涛

01:13:11

行，好，那我没问题。

翠仪

01:13:19

那个呃，我们先休息一下吧，就是先休息一个，这个十分钟以后待会的话再继续讲后面的一个内容。

王蓓

01:13:29

Ok好的，我来设置休息。

翠仪

01:13:46

其实村里。可以啊，内存比较大一点就好。那就是我的，所以说也可以，其实就是慢。妈对你读一个。啊对39你现在不会因为你。一块钱把数量公司的一个。还是晚上。但是那个是那个是训练的一样，推推推推理也行。

许涛

01:14:38

何老师。

许涛

01:14:41

何老师。

翠仪

01:14:42

啊，你说。

许涛

01:14:44

那我再我想再问一下就是呃，如果。

许涛

01:14:47

训练一个像这样一个体量的这么一个一个模型的话。嗯，综合考虑起来大概需要一个什么什么样的一个。

许涛

01:14:56

一个一个配置或者是一个一个一个一个成本或者是个反正各个方面吧，就是或或者比如说时间成本上，时间上啊，或者是呃。

许涛

01:15:06

还有成本上就大概学是一个什么样的一个情况？

翠仪

01:15:10

呃，首先是这个。

许涛

01:15:12

或或者说首先能不能就是咱们能不能训练这么一个东西，我觉得是。一个意思。

翠仪

01:15:16

啊，可以做是可以做的成本问题啊，就是首先你要有这么多的一个数据啊，就数据解决了，你再解决这个呃，硬件的问题。就呃，他们一般训练的时候呃是需要。非常大的一个这个显存资源的，就这个具体的一个训练过程的话，可以参考一下下一次的那个分布式训练的那个课，就是大概就是，呃，除了可能是一台机多显卡都满足不了它的需求，它可能是。呃，多台机多显卡的一个训练。呃，然后可能是呃，我这个我这这个具体我没有做过，但是按照他们给出的一个数据的话，应该是好几个这个a100级别的一个显卡，呃，一个显卡好像这个。哦，我忘了有点这样几万还是十几万，你知道吗？就呃，但是他们用的是那种呃呃企业级别的一个显卡。就你要这个呃低成本一点，可能是用消费级的一个显卡，可能是用呃呃比较多的一个视频90去进行这个训练吧。

翠仪

01:16:32

然后就是显卡？然后时间上的话。就要跟你的这个硬件到底用多少去呃的这个挂钩了，你这个硬件用的越好越多啊，你的这个训练速度可能就是越快。就可能你你用的比较低端一点，可能是一个月或者是几个月才能训练完，就也看你的数据量是有多少的。

许涛

01:16:56

那比如一般一般来看的话，比如说11个月100，万能能能达到车的GRM这样的效果吗？比如说我随随便随便，大概是根据刚才说的，我大概估计，比如说是这么个这么个情况，或者是能达到什么样的情况。

翠仪

01:17:06

100万怎么办？

许涛

01:17:19

你刚才说那个卡光那个卡一个一个卡就好几万嘛，是吧，你十个卡不就得好几10万了吗？

翠仪

01:17:19

好像是十几万，1个卡13万元到8万。

翠仪

01:17:29

这18万。

许涛

01:17:36

然后那个数据弄那些数据是不也得需要很很大成本啊，它那些样本什么的？

翠仪

01:17:41

呃，就你这么说吧，就是那个HP T它大概是这个把2021年某个节点的整个互联网的数据都这个拍下来了。

许涛

01:17:58

光爬也得小时间了。

翠仪

01:17:58

这个是。整个互联网就是只要它能爬到的数据它都来了，这就是这个CT LCD BT，还有GPT是这么厉害的一个原因，它的数据量确实非常多。

许涛

01:18:16

但但是它这个爬数据是不是有法律保护的时候，它是不是也会牵扯一些这样的问题，不知道是不是？

翠仪

01:18:19

呃，这个爬数据你可以理解为这个有想有点像这个搜索引擎，因为本身搜索引擎它就是会定时的去呃爬取整个互联网的一个数据，它这样才能在搜索你搜索的时候快速的给你返回这个结果。

许涛

01:18:41

你比如说咱们去爬百度的数据或怕什么，那会会不会让百度知道了他，他，然后他就，他就会追究什么法律责任呢？还是怎么着这个？

翠仪

01:18:41

嗯，那打牌子肯定是公开的数据啊！

翠仪

01:18:58

或是或者是？呃，但它也有这种，就是这个数据，毕竟数据就是资产嘛，就是如果你本身就没有这个数据，你要从零开始做这个数据的话，我觉得可能还是挺困难的。我们真好是这样。嗯，是呀。诶，你看刚才那个..你加那你这个知识点告诉他，如果父亲的父亲是问那个问题，他..你可以问一下..这个你家。只是他已经出来了，他不知道父亲的父亲是爷爷这一个，所以说不定他没有，你告诉他。如果父亲的父亲是？你看加在这？他这个推理就被其他资料。还是兄弟关系？嗯，对，<笑声>对他的兄弟关系了。那么爷爷就是王爷的母亲。他理解错了。是啊，他们跟他没有第三个，这里其实。把你的父亲的父亲是？他可能要把它放到最前面，他以为是王毅的父亲的父亲是就这个胖的话，其实这么写应该是不好的。那应该怎么写？你你的地标都是，就是第三个没有？对，应该让他去做事情。

许涛

01:21:22

哎，何老师，我在想是。

许涛

01:21:25

咱们现在一般都说这个。

许涛

01:21:27

AI的话一般就是说算力算法和数据嘛，是吧，你实际其实现在这三个里边最不缺的应该就是我觉得算法是最不缺的，现在是吧？

翠仪

01:21:39

呃，可以这么说。

许涛

01:21:41

但其其实也就是那个最缺的就是算力和数据和和那个和数据，这两个是最缺的。

翠仪

01:21:45

嗯，对。

许涛

01:21:51

我现在比如说硬件资源有了，然后数据也有了，那其实就就就直接可以干活了，那反正反正算法都是现成的，是可以这么理解了。

翠仪

01:22:00

呃，是的。他说你是对的。是啊，他是第一，第一条就是王王王上都是，一般都是。所以他这个第三个你可能需要加一些这个bhop去进去呃这个给他。他因为他的这种关系。没有选择正确或者是。就不知道为什么，到了第三步它就是错。说去三分好了70%的。

翠仪

01:22:47

如果用13B的话要用什么？可以。但是实际大家发展的话。基本上是训练的训练。

王蓓

01:23:11

休息时间到啦，要回来上课啦！

翠仪

01:23:15

哦，好的行。Ok那我们接着后面的去讲就是这个。GM二大家的效果也试了，也看到了，这个，你说它很好吧，肯定是说不上的，就呃，特别是对于一些这个比较垂直的理。预的话，它可能就是效果很难达到我们想要的一个预期，但是你普通跟他聊天呢是肯定是没有问题的。呃，所以说的话呢，呃就是针对这样的问题呢，也有了一个这个大语言。

翠仪

01:23:54

模型的一个微调。那他语言模型的微调，跟我们之前所说的一个监督学习的一个追加训练，呃，这种微调，那它其实是有点不一样的。但是黄老师因为早上时常关系理论上这个微调的这个理论部分应该是他。然后就讲完了，然后下午就去直接去告诉他怎么告诉大家怎么做就好了。那这个理论部分的话要放到啊，明天他去讲啊，所以就是说呃这个微调的一个算法的话呢，我们待会会演示两个，一个是这个。Ping这个算法其实本身就是清华是说呃，这个提出来的，所以就是大家可以看到king最常用的一个应用就是在TGOM上面，然后还有一呃，另外一个更通用的叫做这个ra的一个呃微调算法。然后也可以基于这个另一个包去实现。

翠仪

01:24:49

然后的话呢，我们在这里说说的一个指令微调的话，主要是为了告诉大家，我们通常去做这个大语言模型的微调，或者是说大家去看到各种基于拉马这个这模型基座。啊，衍生出来很多的一个模型，然后它这些模型到底是怎么诞生出来的？呃，它的这个数据是怎么来的？然后这个，呃，怎么能微调这么多，呃。这就是其实就是一个，呃，指令微调的概念。那指令微调的话呢，指的是它在少量的一个数据或有限的数据里面呢，呃，它去，呃，通过一些这个核心的一个指令，也要包括它的一个收入。然后帮助模型去获取到这个下任务的一个知识，然后实现的，呃，可能让它可以在某个这个垂直领域下面或者是某个特定的一个任务下面可以获取到更好的一个效果。

翠仪

01:25:49

呃，因为大语言模型的话，其实呃你想从零开始去训练的话，首先这个成本啊就非常高，你要有这个非常大量的一个数据，还要有非常强呃，非常丰富的一个硬件资源。然后烧钱啊，这个花时间啊，去进行这个整个模型的一个微调啊，这个追加训练啊，这好，对于很多这个公司企业或者是个人来说，就是不科学的，那就是这个。

翠仪

01:26:21

能做，但是没有必要，就我们有些时候我们用这个大语言模型，我并不希望他这个十项全能，我只希望他能在我的这个任务上面，然后他能做出他这个比较好的一个效果就行了，哪怕他其他任务做的很。

翠仪

01:26:37

垃圾啊，所以说就我们可以针对特定的任务去进行这个子音微调那子音微调这个概念的话，其实最开始是由这个，呃，就是这个斯坦福的一篇论文所提出的。他做了一个很有趣的事情去这生成了自己的一个模型。这个模型中文译名叫羊驼啊，它这个最开始去拿出来的时候是七p，那他这个他想做大语言模型，但是我没有数据，但是这个它也不可能说像这个openai量。花这个大量的一个人力物力啊，去收集那么多的一个数据，所以说的话呢，它就是呃设计了一个这个self ingestion就呃的一个方案，就它有175个这个。呃任务的一个呃叫做种子任务，然后呢他把这175个任务呢啊给输入到那个CG LM里面，然后让他去回答这个问题，呃这个任务呃这175个任务。的一个问题，然后并且呢，在基于它的这个问题上去生成更多的一个指令啊，去产生更多的一个问答对，然后通过这个方法的话呢？它从175个问题变成了一共是有52K的一个这个呃指令的一个呃输入输出的一个问答，对的一个样本，然后再基于这个样本呢，去把这个拉马。

翠仪

01:28:09

这个拉玛是这个facebook所这个开源出来的一个大语言模型。呃，就是现在facebook叫做这个改了名叫这个beta。但是我们还是喜欢叫它facebook那在这个。就很多的这个代言模型，它的一个底座继承可能是这个拉马这个七P啊，为什么不是这个T GLM呢？呃，首先可能是在国内比较火啊。其次的话大家可以回忆一下第一张图，这个拉马它的技术路线跟那个。呃GPT呃系列是一样的，它都是一个decode模型呃GLM的一个技术路线呢是decode这个encode加decode，大家技术路线呢可能是不太一样的。所以就是他们可能更热衷于说，呃，大家都是，既然大家都是抵扣的，那我用同样的一个模型呢，那我理论上能。用一些少量的数据，就有点像这个模型振动的一个感觉，就我们应该可以用更少的一个参数量，可以达到跟你类似的一个效果。

翠仪

01:29:14

啊，所以说就是这个羊驼这个模型呢，就是通过啊，首先先薅一下这个T GPT的一个羊毛啊，把它的这个啊去让它去给我们去生成我们的一个微调训练数据。然后的话，我们基于它的这个回答的回答是比较好的话，那我基于它的一个回答去进行我的一个模型的一个微调啊，最终得到的一个羊头模型。比如说我这个羊头模型应该是很接近于这个呃，GPT的一个这个效果。所以它就是大家可以经常去看到一些新的开源模型，它宣称啊，我们这边这个相当于多少多少的一个呃，GPT啊，或者是相当于多少多少的一个GPT四啊，这样的一个宣称，它怎么得出这个结果呢？是因为它这个数据的一个产生呢，其实就是通过这样的一个呃self。的一个方式呢，去获取到啊，基于这个CG PT或者是这个GPD四生成的内容，然后再去微调自己的模型，要得到一个新模型。然后这个新模型呢，它可以去评估它的回复跟这个本身这个GPD或者GPT。他的回复的一个。啊，可以给他们的一个相似性去打分，或者是其他的一些打分，然后我们就可以得得出来，比如说就用评分的70%我这个模型相当于70%的这个呃全呃GPT啊，就是这样的一个产生，然后这个指定。呃，数据集的一个生成方式的话，大家可以去参考一下它一个论文也有相应的一个代码，然后具体一点的话可以看这个论文里面所说的一个这个图，它一共是这个700呃175个种子任务。

翠仪

01:31:03

然后呢，它会放到这个任务的一个词里面，然后通过这个呃，机器人呢，去生成一个这个呃指令，然后去获取回答，然后再获取回答的时候呢，它会让它去再去生成一个新的一个指令。然后去得到新的任务，新的任务的话呢，再放到这个任务室里面，它就通过这样不断的一个迭代。就是说第一步我们先手工的去人工去设计啊，这个的话就是呃很有技巧。175个那你可以去。呃，我们自己去微潮的话，去产生这样的一个呃训练的一个数据的话，你就可以根据你的一个业务场景去设计这个呃种子任务，然后每个任务呢，它都会有一个指令输入啊，输出或者是直接一个指令。

翠仪

01:31:53

呃，一个输出，然后呢，它会用这个模型呢去生成新的指令，然后它在设计的时候呢，它会从这个指定的一个种子是随机抽取六个人工编写的，再抽取这个两个呢是模型生成的指令，一个八个。然后呢按照指定的一个模板输入给模型，然后这个模型呢就可以得到一呃，给你一个回复，并且有一个新的指令，你要新的指令也放到这个呃任务词里面，然后最终呃，最开始的时候它是因为我们没有模型生成。比如说它会直接从这个任务词种子词里面，从这里呢？直接抽八个？啊，人工编写的，然后的话呢，我们这个它的一个结果的话呢，我们会用一个呃指令呢去进行一个判断，就是说呃判断一下它的一个呃指令的类别。是不是一个分类任务？然后根据它的判断呢，给不同的输出，如果就是分类任务的话，我就把它呃输出成一个这个。因为因为它的一个呃分类业务的话，一般我们在input的时候有告诉他我们的一个分类的类别，就比如说请判断下面这句话，所属的类别，就或者说在问题一如里面请判断这个问题所属的一个呃类别。去问实体，问属性，问关系等等这些，那如果不是问那任务的话，它就是一个凹的一个任务。然后把它这样的一个不断迭代，不断迭代之后，呃，它就可以获取到了呃，比较多的一个这个指定数据。然后这些所有的数据呢，其实都是经过这个charge PT或者数据这个GPT四去生成的。

翠仪

01:33:41

然后有了这些指令，我们再拿着指令去进行这个我们的模型微调就可以生成不同的一个领域的一个大语言模型的。那呃，目前的一个微调指定数据集的话还是呃挺多样性的，比如说像这个呃，不要这个，呃，这是一个做中文的一个对话的一个开源社区啊，它里面的话呢也是用了这样的一个方式，但是它的一个种。任务呢，可能是有点不一样，因为这个lamer的那个羊驼的那个模型，它用的一个种子任务呢，基本上都是英文的，然后当呃也有很多就是把这个英文任务啊，直接翻译成中文，然后就可以得到这个。

翠仪

01:34:30

中文的一个嗯！指印的数据，但是这个效果呢，可能是一般，因为有些时候这个中英文之间的一个语境存在差异，或者是大家这个生活的环境存在差异，你通过翻译呢，是没有办法很好的去理解的，所以就是这个的话就是基础。

翠仪

01:34:50

跟纯纯粹的一个中文的一个呃，种子护区进行这个呃生成的一个数据。好，当然它也有用自己生成的数据去呃训练出来的一个模型的这个模型，这个呃呃也是基于这个拉马去进行这个微调的啊，有这个13B的，有这个七B的。啊，这个大家也可以去测试一下，跟这个呃T GLM a比一下这个效果是怎么样的。

翠仪

01:35:25

呃，它的这个数据是在这是吧？这个数据集大概是长这样子的，就是它会有一个这个。就是它的一个呃，instruction就是它主指令，然后它输入呢，这里是空的，因为它其实就是一个指令啊，就没有一个固定的一个输入，然后这是它的这个最终的一个输出，这是它。

翠仪

01:35:51

呃，里面的这个？呃，一共大概有50万红的一个数据。大家可以去呃看一下。就它有不同的一个任务类型。它相当于把这些问题输到里面啊，对，就是相当于这个是它的一个问题，要这边都是这个的一个回答。那获得人类的回答之后，他为什么又会产生更多的问题呢？

翠仪

01:36:29

因为它呃，这只是整理过的，它原来的一个这个point呢，就是类似于就是请回答这个问题，并且生成一个跟这个问题相关的一个问题。对对对，然后我就是把问题解析过来，然后就放到那个。呃，作为一个新的问题再去问他。就只要你愿意的话，有的是可以获取到无限多的问题的，就是你可以呃，让他就避免这个不要问题，就是让那个老师，老师对对对对对，有点类似的样子。就是这有点就是跟之前那个模型争斗啊，这个T GPT是一个老师模型，然后我们要微调的是一个学生模型，有点是类似。然后这个模式就永远差不多全了。呃，是的呀，但是它可就可以接近它。啊，毕竟毕竟大家一个是开源的，一个是这个闭源的。就是你可以先用这些问题去得到一个跟他能力差不多的。然后你的可如果在有子领域的问题或者指任务的话，你可以再去进行微调的。这是它的一个呃，数据的一个概化。当然还有其他的，比如说像刚刚所说的，因为这个方法就开始就是S所提出来的，所以它原始的话就是52K的一个。英文的一个指令，然后中文指令的话就是把这个52K的英文指令呢翻译过来，然后呢，呃，同样的可以得到这个中文指令。然后也有一个微调的，就是因为它可能呃这个。有些有些语料呢，跟这个中文的一个场景可能是不符的，它就经过人工去进行这个筛选，可能一般用这个会比较多一些。

翠仪

01:38:36

然后还有就是这上面这三个都是这个呃GPT的，然后也有这个GPT四的GT四的效果一般都会比这个GPT好很多啊。然后它的一个中文数据的话呢，也是经过这个翻译得到的。然后大家如果觉得这个指定数据集有点多的话，也可以参考一下这个项目，这个项目的话呢，其实就是一个呃，度统一的一个指定微调的一个接口。就是它，你可以根据需求，你用这个who啊，然后你想用哪个这个呃，指令数据集去进行微调的时候都都可以用，就是它的一个所有的一个输入输出啊，都是统一的一个接口。

翠仪

01:39:24

然后也可以就是在上面看一下，就是更多的一个数据集的一个情况，就是它这项目本身也有的这个数据集，然后还有就是不同的一个场景的，比如说专门针对于这个代码啊，这个讲故事啊，然后这个呃，对话的。程序得到的一个数据，也有是一些角色扮演过工具指定得到一些数据。然后它一个来源也有标注，那大家可以根据就是如果啊，觉得它这些指定数据是有用的，然后也想去呃，尝试一下微调自己的一个模型，比如说像这个TGLF的一个模型，那它可以在这些这个场景下。得到性能的一个进一步的一个提升的话，那也可以把这些这个数据给下载下来，去进行这个微调。

翠仪

01:40:13

然后看一下它，一般情况下的话呢，微调都可以很有效的提高这个大语言模型的一个能力，特别是这种。参数量比较小的一个大圆模型训练。呃，它跟传统的追加训练不一样，传统的追加训练其实是整个模型所有的一个权重一起去进行这个改变，或者是改变这个部分的一个权重。它这种微调的话是在这个模型上。加了这个议程微调成啊，对，跟这个pen是类似的，只不过大家加的一个地方不一样，原理不一样啊，具体原理明天听到和黄老师讲。就就我这边不去动，那懂讲的是怎么获取的就的数据，嗯，对的候的算法的那个la上，对呀，对呀，对，对，这只是数据的数据的方法是是是是。就有了数据你才能做训练嘛，你就没有数据，什么都不用谈呢。就一般情况下，你可能这个自己的一个场景下也没有那么多这个平铺凹库的一个数据对。

田志军

01:41:23

哎，何老师。

翠仪

01:41:31

就这个，比如说你要做问答机器人的，而你一个企业，你自己本身内部能收集多少的这个问答，这个语料队呢就很难去收集那么多，你看这个人家随随便便就是5万。呃，这个10万的这个只有80万的嗯。就这这都是通过这样的一个方式，我们有了一个基础的一个种子任务之后，再用这个CG PG或者GPT是去扩展我们的这个数据，得到这个数据，再去进行这个微调，那这样可以使得我们这个本地模型可以得到更好的一个效果。然后这一块的话，呃，我们这个用来演示的就待会就是不要讲那个全GPT。嗯，CG LM二的一个微调嘛，呃，我们有一个这个现成的一个这个知识图谱，补全了一个这个指定任务，然后它在这里的话呢，主要是包括这个，呃，他去补全这。就就获取到这个关系三元。啊，这个是也是一个天池的一个比赛啊，这个比赛这个还在进行中啊，大家虽然这个快结束这个，但大家有兴趣可以关注一下后续的一个发展，看一下就是呃这个有什么他们有什么新的一个方案。

翠仪

01:43:03

然后呢，在这里的话，我们可以看到这个数据的一个情况，它是有几个输入的，一个是这个injection就是它的一个指令，就包括它要抽取什么就指定啊，这个已知这个候选关系呃，就是，然后我们去找出它的这个。实体间的一个关系。然后这是它的一个输入，就是这句话，然后这是它的一个output。然后他还需要是说这个做一些这个智能一点的一个股权，就比如说像下面这句话里面，他删除了这个刘德华和朱丽倩，他这个结婚的这句这个。只要他直接就说朱丽倩她生下了一个女儿，然后这个女儿的话呢，后面有一句就是女儿的耳朵呢，像吴德华。然后这从这里呢可以推断出来，这个要从这里推断出来，这个呃刘向惠。他的爸爸呢是这个刘德华，刘德华跟这个朱丽倩之间呢，是一个这个配偶的一个关系。就就是一个其实是一个有难度的东西。

翠仪

01:44:20

但如果你是上面这种的话，其实就呃会相对来说比较轻松，因为它的这个语义比较明确。啊，但这个数据集里面，这也是它的一个任务之一，就就除了这个关系抽取之外，还需要是说在当它的一个一部缺失一段文字的时候，它的这个。呃，能够就从中推理出一些关系。那这个数据集的话呢？呃。我也下载发给大家了，呃放在那个百度云上面，因为这个数据集的话呢，它的一个呃字段呢会比较多一些，它实际上这个最损的话有这个ID有这个呃它的一个类别，然后又指定有输入啊，这个输出。然后就输出还有一个KG啊，我们要做KG的话，它就其实是一个这个列表的一个形式，方便我们的后面去解析。然后呃，为了方便的话呢，我对这个数据集都去做了一个这个呃处理预处理的一个部分。

翠仪

01:45:29

诶，那个是哪位同学没有闭麦吗？

田志军

01:45:30

唉，何老师，我想问一下，就是刚才您上面讲的是呃模型的微调，咱现在讲的是呃制图补的微调，这两个之间的这种关系是什么感觉有点跳，然后没有理清楚它俩之间的逻辑关系。

翠仪

01:45:55

哦，没有讲到知识图谱的微调，这是一个知识图谱的数据集，用来做模型的微调。

翠仪

01:46:04

跟上面的这种指令数据是一样的意思，只不过它这个数据的一个呃范围就是这个领域是在了知识图谱这里。

田志军

01:46:18

这这个是对知识图谱的进行微调，还是对知识图谱上面的大圆模型进行调整啊？

翠仪

01:46:27

这个只能说是对大语言模型的微调，它针对的一个这个任务是知识图谱的一个呃关系抽取和关系股权。

翠仪

01:46:40

它本质上就是一个呃指令的一个数据，有一个这个呃，输入有一个这个输出这样的一个结构，所有的这些数据我们都有这样的一个结构的数据，我们。都可以去做这个大语言模型的一个微调，那因为我们课程本身就是要去讲这个大语言模型的这个知识图谱的一个应用，所以我们这个微调的一个示例数据。用的是这个知识图谱关系抽取的一个指定数据。

田志军

01:47:17

好，那我理解是说你调整的这一部分，这个数据是调整大元模型，抽取是图谱实体实体关系这一部分的能力是这意思吧？

翠仪

01:47:28

啊，对，就是你微调了这个模型之后，你可以把呃，把这个在原模型进用到一些这个新的一个语料上面去进行这个知识抽取。

翠仪

01:47:51

Ok那个回到我们刚刚所说的，因为这个数据它的一个输入的一个字段呢，是有点多的。而这个K GLM它提供的一个官方数据的话呢，呃，它是只有一个input，一个output就两个字段，一个输入，一个输出。所以说的话呢，我在这里去做了一个这个呃。因为这个这个这个脚本啊，有没有全？这个数据的一个预处理，主要是，呃，把它的这个数据呢，呃，增加了一个这个输入的一个字段叫做all input，然后这个就是把这个它的一个指令和它的一个输入呢结合在一起。就是加上一个呃输入的一个。这个数据生成后呢是这个样子的。然后它本身是一个呃jon L的一个格式，虽然写的是jon，就是这是一个jon，然后一行行的jon，然后我们最终给到模型的话是，这是给模型输入的一个数据。叫做a，然后就是它的一个out的一个数据，或者是你用KG这个输出也是可以的啊，就这个呃，无没什么所谓，就是这两个字段表示的是一个意思。

翠仪

01:49:27

Ok这个数据的话呢，我是放到了这个呃GLM它本身有一个PT这个呃目录呃这个文件夹下面，那这个PT的话主要就是去做这个呃GLM二的一个微调。然后我把数据放在这啊！然后它微调的一个呃方案的话呢，这个流程呢是这样子的。

翠仪

01:49:58

它首先的话呢，呃需要安装一些依赖去对这个数据呢去进行这个呃。更新，然后它的一个呃，transformers一个支持的一个包的最低要到四点二点七，呃，四点二，七点一的一个版本，那如果你说你那个本身装了这个M二的时候，它就是要。我的已经升级到了三D4.30的一个版本就是没有什么问题的，然后就是它的一个输入输出的一个数据。然后的话呢，呃，我们去做P均点的时候呢，它直接是有一个这个脚本文件，就是这个train的一个脚本文件。

翠仪

01:50:44

我们需要修改的是它里面的这个呃路径，所以我另外写了一份啊，就避免这个给它这个重复了，首先是这个啊，我们这个训练的一个训练级的一个路径。和这个呃验证集的路径都是这个追审的一个格式。然后这是一个参数的一些设定，然后呃，最重要要改的就是它这个模型，它的一个路径啊，就是本地的路径。呃，因为它默认的是这个，呃，网络就是那个H跟上面的一个路径。然后就会下载，然后其他的话，呃，我也修改了它的一个最大的一个输入和目标的一个输出的一个长度，因为考虑到它输入的饮料可能会比较多一些，那你可以甚至进一步可能给它改到500字的一个输入。也是可以的，因为它本身它就比较长了。然后就是它的一个输出啊，可以根据实际采改，那可能就是没有那么多输出，因为它只是做那个抽取的话，然后就是其他的一些设定啊。然后这个改完之后的话呢，我们就可以直接去运行。这一个。

翠仪

01:51:59

啊，这个县城都到了，嗯，这个可能就是比较问题，问的比较多。显存显存显存是只有那个24局？就跑跑跑两个模型就不行了。所以CD到那个PT里面，我们把刚刚所说的那个改了之后啊，就包括第一个是这个data里面，我们把这个data文件夹上放上去，然后data我已经处理好了，你可以不用再处理。但是如果你有自己的一个数据要去。去做的话，你可能就是按照它的格式呢去调整一下。然后第二个就是训练这里啊，我们的这个呃，训练的一个位置，然后还有就是我们的一个输入输出的一个字段啊，一个叫做这个all input，一个叫做output。然后它本身的话是不叫这两个名字的发生提供的一个样例数据？然后把这些都改完了之后呢，我们就可以直接去运行这个呃。

翠仪

01:53:08

这个命令。去进行这个训练，但这个训练的话呢，它会比较费时间，所以我也只是。跑了一线。然后它的一个输出呢是在这？那我可以看到了，我这个checkpoint呢就是保存了一些。这个是这个训练呢，大概是迭代到了呃，1000的时候它自动保存的一个。然后在这里呢，它会有一个问题，因为我们现在是用命令堂的，然后它其实它训练的时候呢，它是有一个可视化的一个界面的。但是因为我们现在是这个没有可视化界面，所以我们选三就好了，就不要呃，可视化我们的一个结果，然后只是这个做一个文字的一个输出就好了。

翠仪

01:54:06

然后大家可以看到它一共要跑那个呃3000your step然后这个大概呢是要这个九个多小时吧，就我也没有跑完，大概跑了1000个step之后我就停了，因为这个。呃，时间也有。然后呃。

翠仪

01:54:27

大家呃，如果有兴趣的话，可以把这这个3000个这个step就把整个这个微调的一个过程呢给它跑完。那跑完之后的话，其实这个微调过后的我们会得到，就比如说像这样子，我们可以得到一个微调的一个权重，那大家可以看一下它的呃，这里有显示这个大小吗？没有显示这个大小。那我这我就呃不继续跑了，因为待会要加载这个模型。那就先停了，然后这个大小呢，其实它呃是比较低的，就是这个。这个这里可以看到我们的这个模型承重就没有几个大的一个模型，就这个最大的就是这个七。

翠仪

01:55:20

和这个是是M？那我们这个权重呢，是要结合到它原来的这个，呃，模型的权重一起去使用的，不然你单有这个最佳训练的一个权重呢，是没办法训练的，因为这个这这个微调这个微调只是保存呃，这个微调层。的一个权重，因为它语言模型它本身的一个权重是没有发生任何改变的，是在冻结的一个状态下，我们去跑这个，呃，去训练这个微调层的一个权重。所以在这里的话呢，我们得到的这个微调之后的一个结果。这一个权重呢，是一个比较小的一个模型，那在推导的时候呢，是需要基于我们原来的一个模型呢，一起去这个，呃，使用的。那它这个使用的一个代码的话呢？啊，因为我原呃，这个这是网页上写的，然后我加上去的一个代码，这个代码也发给大家了，就是它需要啊，首先把这个这个**呢给它加入进来，然后也需要把原来的模型呢给它加入进来。然后这里的话呢，可能是我们这个最长的输入呢是512。这里我们可以设定一个呃，就是我们追加训练的一个tr的一个路径啊，就刚刚导出的是这个output在我们这里也写out那你可能呃，因为它最终没有跑完，所以可能要到这个。去碰这里。

翠仪

01:56:59

那我把这个路径给写全？然后呢，它会把这个路径跟这个呃，我们得到的这个模型权重，这个并文件的话一起去加载进来，然后的话呢，通过这个语句呢，去把我们的这个微调成。的一个权重跟我们原来的模型权重结合一起来使用。诶，我这个都还没有加。

翠仪

01:57:55

一下这个。就是它这里的话是在加载这个XGOM的一个呃，本身它自己的一个模型。哎呀，怎么这么多户没有装测试的时候？

翠仪

01:58:46

嗯，我是我新练的时候好像只写了128哦，对，这不是我刚刚训练的。然后它在这里呢，其实已经加载完了，我们也可以去呃，把这个模型变成一个这个放到复杂上面，然后变成一个这个呃验证模式。当然，如果你觉得你的呼打可能不够的话，也可以加这一步去做这个量化，你训练的时候呢，它本身呢也是有一个呃，量化的一个参数的，但是这个量化参数的话，因为我下载的本身是一个全量的模型，就不是一个量化模型。所以我把它删掉了，就是如果你本身下载的那个呃。Charge M是一个量化的一个模型的话，那你可以去把它一个量化参数给它加上去。然后这是那个在他的一个验证集里面去找的一个输入的一个样例。我们可以看一下它的一个呃预测的一个结果。就是它的这个预测结果就是这个银库是这样的。呃，你可能是会比较好奇，如果没有经过微调的话，他能不能这个找出来。哦，我们现在找一下那个。那去GLM他有在这个群里面随便找个群问他一下就好。那这个方案的话，你也可以去跟这个没有经过任何微调的这个，比如说这个GLM。还有就是。就是它的一个这个回答，你可以看到它这个原来就是没有经过微调，它的回答呢是这样子的，然后就是经过微调，它的回答呢是这样子的。

翠仪

02:01:03

那大家可以可以看到，而且这个我训练只是训练的，大概是1000个step你说他这个收敛的话，可能还是离收敛还是有一定的一个距离的，但是可以看到，经过微调之后，首先。它就是，呃，很明显它输出的话是完全符合我们的一个需求的，它不会有这种什么啊，根据什么什么这个这个有的没的这种东西哟，然后后面还有这个其中什么什么，哎，这种无聊的东西其实对于我们。后面去做这个知识充取是完全没有用的，所以就是模型微调的话，你可以很好的去呃，让这个模型在一个子任务上面，按照你所需要的一个数据的一个格式去进行输出。那把避免它输出一些这个有的酶的东西，然后我们后续去解析的话，也是更方便去解析，那就是，呃，就是它这个微调之后的一个模型的一个呃，输出，就是它原来没有微调过的一个模型的一个输出。可以看到它这个输出的这个完全是。跟我们想要的这个差很远，就什么位于机场这个什么机场，这这什么东西你可能就完全是没有看懂，但是呃你经过微调一下的话，你就可以得到一个呃好用的起码是能用的一个结果。

翠仪

02:02:26

那刚刚也给那个呃GPT这个发了，你也可以到它能抽取一部分的一个数据啊。呃，但是没有抽取权。嗯，就是这样子。然后你可再可以跟那个呃GPT四去做一个比较。但是PPT四呢，他就慢一些。呃，它跟那个JPG3.5的就是结果基本上是呃一样的。那你们可以去自己去对比一下。

翠仪

02:03:10

好，我们其他的那个？呃，就如果你魏桥足够多的话，它很有可能原来的这种。就普通的一个聊天功能可能就已经丧失了，但是他只能去用于做一些特定的一个任务。就是微调它有有好也有坏。Ok那个呃GLM的一个的这个微桥，还有包括这个微桥后的一个模型的一个使用这一块流程上有没有什么问题的？

翠仪

02:04:04

如果没有的话，你就继续去奖励一个这个微调的一个课文好，你说。

王波

02:04:06

呃，你好。老师你好，那个我之前就是根据网上的一些。

王波

02:04:14

资料啊，就指导那个我也调了一个微调，然后就是那个好像衣服的好，大家好像都很常见，那个这个微调的一个案例。

王波

02:04:24

就是说发生了，你刚才说那个情况就可能是过拟合了什么的，然后他就把。

王波

02:04:30

把那个其他的回答都都变成那种微调的回答。就出一个你好的，都是都回答不出来了。

翠仪

02:04:35

啊，是的，是会存在这种情况，就一般情况下的话呢，呃，我们去做这种呃比较小的一个任务的一个微调，因为比本身我们的一个数据量可能跟它原来一个数据量比，就是确实是九牛一毛。

王波

02:04:40

就这种事情？

翠仪

02:04:57

非常小，然后这个训练它足够多之后，它这个很容易就是过滤，就是这样。微调过后的话，这个代语言模型在这个任务上的一个效果会非常好，但是它可能就丧失了一些其他这个场景上的一个。呃，能力那一个解决方案就是说你可以把你这个代语言模型，你想让他做的这个用户场景。就比如说除了去做这个，呃，这是数据是这个呃关系抽取的，你可以把这个实体抽取的啊，这个属性抽取的这些指令也一起放到这个微调的数据集里面，就它这个数据集，它微调的指令数据集，因为它指令不一样。但其实可以包含很多很丰富的一个内容，包括呃，你想让它去生成这个呃。查询语句你有语料的话你也可以去。要放到这个微调原料里面，就尽量让你的微调与要覆盖到你要用的一个场景里面，再去进行这个微调，那这样的话就不会让他说，就是你这个在别的这个场景下啊，我这个就就就就用不好。

翠仪

02:06:12

然后。

王波

02:06:13

对，我的意思就是说。呃，就是说我在解解决我这个专业问题里面的东西，他都只只能回答我专业问题，你这样也是只能回答我专业问题，那么我通用的一些问题。

王波

02:06:29

是用两个模型来？来来做再再再调另外一个通用的模型嘛，回答做一个真正机器人的时候。他通过问题也要回答呀，这事怎么办？

翠仪

02:06:37

然后。就通用问题的话，其实你也可以把你通用问题放到你的这个。这个微调的这个数据里面。

王波

02:06:51

但是我但是我没有他那个。

翠仪

02:06:51

这是一种解决。

王波

02:06:53

就是GLM他们自己微调的那个数那个数据啊？

翠仪

02:06:58

呃就就就你可以跟那个这这这这这很多指令数据集这些都是很多通通过领域的，你在里面去抽一部分啊，放到你的这个里面，然后你给它指令可以是设定是说。

王波

02:07:06

这个。

翠仪

02:07:16

呃，你是一个普通的聊天机器人，然后这是我的问题，然后就把用户的问题给它输入进去，那它就会切换到这个聊天机器人的模式了。然后比如说你要做这个实体抽取的时候，可能就是给它举一个指令，就是说请把这个这个下面句子。里面的一个实体给它抽取出来，这实体的类型是什么？然后句子是什么？嗯，那这样的话它就可以统一用模型去适配不同任务。其实大语言模型它开发出来就是希望呢，它可以用一个模型去适配不同方向的一个任务，而不是像之前那个but的时候。

王波

02:07:37

嗯。

翠仪

02:07:52

它不是，就是你做不同任务，你可能就是要去做不同的一个追加训练，然后你得到了不同模型，你要不同模型要分开使用。

翠仪

02:08:01

呃，就大于模型的话，它更更希望更更希望能做到一个效果，就是一个模型，能把你想用的这个，呃，想做的一个领域给它覆盖掉。

王波

02:08:14

嗯，明白，就是我刚才也想要问这个问题，就是说你刚才那些呃指令啊，羊驼那些就是抽通过GPT抽到的一些指令的一些数据集啊。

王波

02:08:26

这些数据可能是的一部分，它可能不全面，那么我这样。加上我的专业领域的一些指令集，然后训练出来自己的一个对话，机器人的话，可能在通用知识回答上面可能就会比较差，会不会这个情况？

翠仪

02:08:34

嗯，对。呃，就，呃，如果你在追压训练的时候，其实你要加入一些这个，呃，通用的一个对话，并且在这个指令上面可以一个比较明显的一个区分的话，一般是不会的。

王波

02:08:57

哦，对，但但是我的。就是我。就是我们现在应该是没有清华他们那个开源的那个数据集是吧，要自己做一个。就是通用的数据。

翠仪

02:09:07

对呀，没有清华它那个数据集其实是呃，一些学术机构里面这个给它去用的，所以就是呃，它并没有开源这个数据集啊，就就应该未来也不会去进行这个数据集的一个开源。

王波

02:09:26

对，所以训练出来。就是最好的结果可能也不会，就是通用问题的回答可能也会比较也会也也赶不上，他们应该也是比较差的，应该是这样吧。

翠仪

02:09:35

哦，你跟那个GPT和这个呃GPT是比的话，肯定是差差了一大截。

王波

02:09:43

不是，我就是说和GLM相比，我们就用我们自己通过上面羊驼啊那些。

王波

02:09:51

呃，开源的一些数据集，加上我们就是知识图谱，刚才的一个指令数据集来训练出来一个这微调的一个G IM，那么这时候它。

王波

02:10:01

的通用问题回答的这个GLM是不是也比清华他们这个原原原本的这个GLM是通用问题回答会比较差一，相比会差一点的。

翠仪

02:10:02

呃，应该不会差一点，就我觉得可能会好一点。

王波

02:10:15

可能会好一点。

翠仪

02:10:20

嗯，对。

王波

02:10:20

哦，就是。我我就是发现他这个遗忘的很严重啊，我可能就有点儿，是不是训练的步骤太多了，我我就按他那个网上来的，就训练3000步，然后问问个你好，他都是回答那个什么什么就就不错了。

翠仪

02:10:35

可是他就很，就比毕竟他给的那个要命数据本身就比较少，然后他很容易就是过离了。我之前去那个测试的时候也会发现这个问题。

王波

02:10:43

啊，那你怎么解决呢？就是说。嗯。就是说训练步骤少一点嘛，还是怎么解决这个问题？遗忘的问题。

翠仪

02:10:57

呃，就就就是刚刚所说的，就我尽量是在微调的时候去调整一下它的一个，就增加一些这个日常对话的一个语料进去。

翠仪

02:11:08

就覆盖到我们所使用的一个场面，但有些时候的话，其实我是不需要他这个日常正常对话的一些能力的。就有些时候去做一些这个呃，有点类似去做but的一个下游任务，我可能只是针对几个场景需要它的能力而已，就其他场景正常聊天可能是不需要的，那这时候我就不需要care这件事情了。

王波

02:11:34

嗯，好。我还有一个问题，就是说刚才您讲那个指定微调的时候。就是通过学习JPT的回答来做一个指令微调指令微调的一个数据集，然后就训练出其他各种不同的模型。是这样吗？

翠仪

02:11:49

哦，对。

王波

02:11:50

对，我这我的问题就是说。呃，如果在这这种情况下，那么其他就我们训练出来的和GDP不一样的模型。呃，那回答效果呃，暂且放在一边，就是这就是我们和就是我们这个训练其他的和GDP不一样的模型的时候，这数据集只有在只能微调上不一样，其他的数据集怎么办呢？还有其他数据集吗？

王波

02:12:14

还涉不涉及到其他数据？

翠仪

02:12:16

你说其他数学级是指这个特定领域的吗？

翠仪

02:12:21

比如说像这个知识图谱构建这样子的。

王波

02:12:24

嗯，不是就是通用的一个，比如说你刚才说那个拉嘛，我们用了。

翠仪

02:12:26

它，它这个其实都是通用领域里面的一个数据啊，你可以看一下它的一个，呃，输入的一个样例，它就就是一个很通用领域的呀。

王波

02:12:29

对呀。对，我就说这些，这是和JPT学到的指令微调的。

王波

02:12:43

数据集吗？还是说还有另外的一些数据集？

翠仪

02:12:47

呃，不太明白你说的另外的数据集是？

王波

02:12:49

我我的意思就是说，你不是通过和GPT对话来得到一些指令微调的数据集嘛，是不是？然后我用这些数据集来训练一些？呃，其他的比如说拉嘛，这种模型是不是？那么，辛德拉姆的模型除了和GPT学到的这些数据集之之外，还是什么数据集吗？还是说只用这些就够了？

翠仪

02:13:10

它是这个数据集，只是用来做微调的。嗯，就是提升他的能力的。

翠仪

02:13:18

就它不是一个预训练所用到的全量数据集。

王波

02:13:18

噢，明白了，就是说，比如说训练拉姆的时候，他他之前的那些数据可能是和GPT四GPT三应该是不一样的。我只是在指令微调的时候和GPT四学一下它的指令微调。

翠仪

02:13:31

对对对对。

王波

02:13:37

哦，好明白。

王波

02:13:43

好，谢谢嗯。

翠仪

02:13:44

嗯，ok呃，就是这个的话，在它的这个G LG LM二的时候呢，它也提供了一个全量的一个微调的。

翠仪

02:13:58

去个脚本。嗯，叫做这个呃DST。这个。就它可以对整个GM所有的一个模型权重啊，去进行这个呃微调，但是我这个不敢跑，我怕这个呃显存一下子就炸了。就如果大家有需要的话，也可以去用它的这个全量的数据集，然后它需要用到的是一个叫做的一个框架，呃，这如果显存足够的话，可以挑战一下。嗯，这是这是于他官网所说的。

王波

02:14:40

啊老师，我老师我还有一个问题，还有一个问题，不好意思，还有一个问题就是说呃我当时用的，因为我显卡只有八个G嘛，当时用的就是那个量化那个，然后。

翠仪

02:14:43

哦，你说。然后。

王波

02:14:51

微调的是不是和这个有关系？如果你不用量化的话，就是是不是效果可能差在这个原因有没有可能？

翠仪

02:14:55

呃，那肯定是量化的这个效果跟这个原始它的一个效果啊，就是有一些差异的，但具体差的差异多少的话，就没有一个很好的概念，就只能看大家去自己去评估。看的就这个建议的话，就是有这个显卡资源的话，还是尽量用它呃，这个原来的一个模型精度。

翠仪

02:15:23

这样会好一些。

王波

02:15:25

哦，我对这个遗忘感觉很震惊啊，好，谢谢！

翠仪

02:15:34

Ok就是那个呃，PT的一个方法，然后也是在这个呃，我们的这个呃H GLM它本身自带的一个方法，然后另外一个就是这个lora的一个微调方法的话呢，呃，它也是一个很。通用的一个微调方法，然后呃它的一个具体原理的话就交给黄老师，明天去讲了，我这边就不抢他的活了，就怕他那个呃，大家有兴趣的话，明天认真听一下，然后在这里我们讲它的一个实现。

翠仪

02:16:08

就是呃，lola的话，那你要实现也非常简单，它有一个这个H跟F推出的一个户叫做PE FT的业户啊，它是一个这个参数，这个高效微调的一个简称，然后它里面就封装了这个lora的一个这个。方法。然后可以适用于各种下游的一些任务啊，就不需要整个参数模型，这个整个模型一起去这个微调它的一个计算成本呢，这个组成成本呢，就可以大大的一个降低。它里面除了这种的话，还有其他的这个呃微调的一个方案，包括这个P，然后PT的话，呃，这个GLM里面所提供的一个代码的话，它内嵌的是一个V二的一个版本。

翠仪

02:16:56

LPFT这个who的话，它是还是一个P一的一个版本，还没有更新到P二的一个版本，所以大家如果要去对这个呃CM系列去进行这个PT微调的话，建议你。是用它本身自带的，就是这个呃，脚本去微调会更加好，效果会更加好。就它的这个V二版本的话，它对这个性能的一个要求呢，就进一步的一个降低速度就更快，大概是这样的一个效果。

翠仪

02:17:28

然后这个呃who的话，它部署的话呢，可能会存在这个一些问题，就跟我们原来的环境会有一些冲突。呃，所以的话呢，我是封装了一个这个呃新建的一个虚拟环境。然后的话呢，它主要呢是在于这个。它版本的一个限制，它官方的一个要求是，这个特权呢，是在一点一三点一以上，就最低的是这个版本啊。所以呢，我就只能去在虚拟环境里面去装了一个新的一个特殊版本，然后装了一个新的用户版。呃，大家如果要装的话呢，呃到时候的话我会把这个镜像给大家装好，然后如果大家自己需要的话呢，呃也可以去自己去更新一下，因为呃不打11.3的话它支持不了1.13这么高的版本。啊，所以就是升级了一个比较高的一个互打版本。然后其他的这个倒是没什么这个要求了，然后呃这里借鉴了一个叫做。下就要清冷的一个户。去完成整个基于这个呃，就去完成整个lola的一个微调成的一个训练。然后这个P的话呢，它这个呃原本是做的这个CG OM的二的一个版本呢也同样适用，然后它的一个效呃要求的话，硬件要求的最好就是有24G以上，那显存的至少是要有16G的。然后拍成的话需要呃3.8要不打是至少是11.6的一个版本。然后就安装我们的一个需求就好了。然后的话呢，它这里给的一个样例呢，是做，呃，去把那个量多的一个数据集去做处理。

翠仪

02:19:29

然后杨头的数据集呢，它本身是一个呃，jason的一页格式，要把它变成一个JSL的格式，然后我们接着呃，就是还是就刚刚的那个呃知识图谱呃关系抽取的一个数据集的一个。呃，追审的话，我原在原先在做预处理的时候呢，就已经把它写成一个追L的格式，所以这一步呢，我是跳过的，但如果你们要做其他数据集的一个微调的话，那看一下它提供的是一个追审的一个数据集还是追。高的一个数据集，那如果不是追省的话，那你可以通过这个脚本呢，去转换成这个追。然后第二步的话，它是预先把它的一个通过呢，先给它生成固化下来，那这样的话呢，就可以直接在后面的时候，呃，训练的时候呢，每次训练啊，包括你中断去接压训练的时候，你就会直接读取到它的一个固化的一个通过来。呃，不需要再去做一个通过来这样的一个步骤就，呃，降低我们训练所需要的一个时间。所以在这里的话，我也是预先已经做了啊，这个包的话呢，我们先把它拉取下来到这个本地上面啊，就就是克隆一下，然后就是呃，好，按照它上面去安装一下这个所需要的库。

翠仪

02:20:51

那在这里的话说，呃，有一个句意的一个点就是第一个呃，我们这个安装这个库的时候呢，呃。首先呢，这个touch的话呢，如果你本身的版本不是这个一点一三点一以上的话啊，你可以把它注释掉，你先安装你的这个特权版本，因为它一般通过这样的一个方法去安装的特权版本。都是CPU版的啊，没有GPU版的，所以就是touch的话最好是自己去安装一个呃，对应你扑打版本的一个呃版本。第二个就是它原来的这里写的是通过这个概括上面。去安装这个PFT的一个库啊，那不用那么麻烦，因为这个最后不一定是每一个服务器都能连得上，所以你最好把这个注释掉，直接写成这个BF T直接P IP安装的话呢，它就是一个。呃，大于零点三点零的一个版本呢，这个是ok的。当然如果你觉得你的版本还有问题的话呢，呃，你也可以把这个呃包直接去下载下来，然后直接用python set到点PY install的一些方法去安装，那它最新版本好像到了零点四点。

翠仪

02:22:12

您的一个版本呢？那就是这个安装它依赖的时候呢，呃会出现的一些问题，然后第二个呢就是在转换这个，我们不需要执行这个呃，通过来把它这个呃通过去固化下来吗？在这里的话呢，我们需要。修改一下这个模型的一个路径啊，因为默认都是这个联网的啊，我们都是在本地有这个模型的，所以修改一下这个模型路径就ok了。然后我这个数据的话，我是把这个呃。

翠仪

02:22:46

训练的刚刚就是刚刚做的那个数据集放到这，然后它这个固化之后呢，就可以得到这样的一个呃，矩阵的一个数据。然后我们训练的时候是直接读取到这个呃文件夹里面的这个数据。去进行这个训练的。然后就是，呃，第四步去做这个organization需要修改权重，那第五步的话呢，这个by的一个脚本的话呢，我们也需要把这个by的这个脚本里面的一个模型，权重的一个路径呢，给它修改一下。啊，还有这就两个地方，一个是它model的一个是tation的一个模型的一个初始化。然后我们输入的这个参数的话呢，这个第一个就是它的一个数据的一个路径，那就是看上一步我们保存在哪里了。那这是这个模型路径，然后它的一个呃，罗拉的一个rank，然后它的一个B size，然后这一步跑起来的话呢？呃，可能这个step数可能是不太一样，如果是这个3000个step的话呢，它会比这个。他会比那种CD到这？先到这个目录下面。它会比这个PT点要快一些吧，可能。哦，不行我这个。是这个模型没有关。那应该是要保险存错了。

翠仪

02:24:51

就它所需要的时间呢，是同样的一个step的一个情况下呢，它所需要的时间呢，会更短一些。单纯这个时间关系我还是没有把它跑下来。

翠仪

02:25:07

然后这个结果的一个对比的话，呃，可能要明天再跟大家去对比一下这个结果。呃，因为这个这两种这个微调的一个方案，目前也没有人说是哪种方案确定是会更好一些，所以就。呃，只能说呃，看大家的一个取舍，大家可以听完它们的原理之后再判别一下到底自己啊的一个场景更适合运用哪种方呢？那很多很很更多的时候，可能就是实践出真知，因为就是呃，有些时候你也说不准它到底是我这个某个特定场景，它到底哪条哪种的一个微调方案呢？会更加好一些，那跟那个。

翠仪

02:25:52

呃，PT的一个微调一样，它的一个模型的一个加载了，同样也是需要把它原来那个模型加载了之后呢，再把我们的一个微调层加载进来，然后去做一个合并的一个操作，然后就可以再去进行这个推理了。啊，大概是这样子的一个操作。

翠仪

02:26:17

呃，那说到这的话呢，也给大家说一下这个拉马拉马这个是非常多的，这个，呃，就是大家的一个实验对象，就各种的一个模型，大家可以看到很多模型的一个底座呢，其实都是拉马这个底座。呃，就这个可能是因为首先它技术路线呢是跟GPT是一致的，大家都是这个decode的一个模型。第二个的话呢，就是说，呃，它的一个模型公开的一个权重呢，呃，不同的一个权重都有什么六。呃，这个七B啊，13B啊，呃33B啊等等的都有啊，大家呃可以非常不坏的去根据自己需求去进行微调，那就是一个这个具体的一个方案，就就就就他做了呃去做什么样的一个数据。

翠仪

02:27:04

啊，去做什么样的一个微调，我们可以得到怎样的一个模型？到现在很多呃爆出来的一个模型，其实底层的一个模型技术就是拉嘛。但他把它原生训练的一个模型的话呢，呃是用英文的一个语料去训练的啊，虽然加入了小量中文，它原生的模型对中文支持的非常垃圾啊，这个大家都不用试了啊，大家要试的话可以试一下。用一些中文的一个指令去微调过的一个拉马模型啊，效果会好一些，但是用，因为它原生模型，它这个对中文的支持度会比较低一些，所以就是刚开始用中文的这个。比如说像刚刚所说的这个羊驼的一个数据的指令，去对它去进行这个微调啊，中文的一个数据集去进行微调的话，效果也一般，但后面可能也有，那么GP四的那个版本可能效果会好一些。

翠仪

02:28:03

那大家有兴趣的话可以去研究一下拉玛所衍生出来的各种模型的一些关系。就是就是呃它们的模型结构其实都是一样，就是数据集不一样啊，可以这么去理解。

翠仪

02:28:26

嗯，就是之前我看到的一版的一个叫的这个中文词表的一个模型，但这个当时我测试的时候，这个L码就是连GM都不如，就效果比较一般，但后面就会它有一个比较大型的一个权重，其实是有。开源的啊，但不是一个公开的开源，就是大家可以想办法去拿一下，就是最大的一个权重啊，去用它那个再去做的话，效果会好很多。那这是这个呃这个呃微调，还有就是lama这个模型的一个简单介绍。呃，这一块应该没有什么问题吧，大家有什么问题需要去继续去讨论的，如果没有的话就会时间关系，我们可能要继续。

杨雪毅

02:29:17

呃，何老师听得见吗？

翠仪

02:29:19

听得见你说？

杨雪毅

02:29:20

呃，我就想我想请问一下，就是说部署的时候它是这个，就这个它是可以多考部署的，那微调的时候是不是也能够这样做呢？

杨雪毅

02:29:30

就多卡的时候。

翠仪

02:29:32

哦，多少微调吗？还是说微调？

杨雪毅

02:29:34

多卡微调。

翠仪

02:29:35

哦，支持的就多考，微调是支持的。它原来的一个代码也有这个多卡的一个代码，只不过是因为服务器上面。呃，就是只有一张卡。你可以看它的这个。它这里有设定这个呃，训练的一个节点数，就是它的一个，还有这个GPU的一个数量，你可以去多卡分布去进行这个微调，但是单机的还是。

杨雪毅

02:30:08

哦，那还是单机的？哦，谢谢谢老师！

翠仪

02:30:31

Ok那如果没有问题的话，我们就去讲今天课程的一个最后一个呃，这个内容就是一个lunch的一个呃。拍手库那这个拍手其实是一个呃，对于这个LOM做一个非常好支持的一个工具，那它可以基于这个呃，learchen这个框架呢是非常方便的去构建一些聊天机器人呢。这个呃，像我们这基于销量搜索的一些这个呃摘要，还有这个问答，然后还有就是他也可以帮你去查库啊，去做一些这个数学难题和这个推理谜题啊，都可以去做。

翠仪

02:31:14

那这个呃L呢是现在也是呃，基于这个大语言模型底下一个非常火的一个拍成库啊，大家可以去到它的一个地图上面啊，去看一下。呃，然后它的话呢，其实是一个因为是一个应用框架，所以它怎么去用的话，就完全看你这个对于这个问答机器人或者是其他的一些应用的一个需求，但是它提供了很多方便，便利的一些工具。

翠仪

02:31:45

那呃，也提供了为不同的一个模型呢，提供的接口啊，包括这个呃，主要还是这个open AI的一个系列，就是如果你有open AI的一个key的话，你可以非常方便快捷的这种几行代码去构建起你的一个应用性。然后它也有本身自己的一个这个长记忆，就是这个呃对话的一个记忆功能，比如说呃，大家可能是会看到这个，呃，不知道大家有没有用过BE的一个呃，新的一个搜索引擎。就是他搜索里面呢，会有一个聊天的功能。

翠仪

02:32:23

然后聊天这里的话它会记住了，之前我问过他的一些内容，你可以就是呃，这这个就就就之前的内容呢，继续去问他一些问题，比如说像我之前问他的一些线上数据库的一个介绍啊。然后还有就是。啊，其他的一些内容等等这些都可以记录下来，然后你可以就之前的一个聊天的一个话题去继续去询问，然后这个是可以通过这个lanchen里面的这个呃，memory就是它的一个记忆功能去换。存一下我们的一个对话内容。然后这是这个中文文档啊，还有就是这是它的一个官方的一个文档。呃，中文文档的话呢，呃，它可能有一些就是翻译的界面转跳，可能会有一些这个经常会到这个市民市的一个界面，然后就是有一些这个API，如果你想看的话，可能它跳到这个视频是它没有相应的一个翻译。

翠仪

02:33:24

呃，所以建议大家还是呃，首要的话去看这个英文文档就好了，然后它的一个安装呢也是非常简单，一行命令就可以了，因为它本身不涉及太复杂的一个东西。

翠仪

02:33:40

嗯，这个我就先停了，空再跑。

翠仪

02:33:54

就一行命令它就可以装了，它安装的一个依赖的也是呃，基基本上我们要用的都都都都在上面。呃，上面那个呃，所以就是没有什么可说的，这个安装就没有任何的一个难点。然后的话呢，呃，它这里官方的教程呢，其实都是基于这个open AI呃，去做的一个聊天机器人，那这个为了方便我们的这个实践的话，所以我。待会儿的一个讲解呢，会掉了这个tag OM。二的一个模型去做啊，这样就呃有有些同学如果你自己有open AI的一个账号的话，也可以参考这个官方的教程，设定一下你的一个open AI的一个key，然后呃连一下open AI就可以了。就它其他流程都是一样的。然后呃，如果你想用一个谷歌搜索啊的话，可以安装一个谷歌搜索的一个插件，然后如果你想用其他的一个相当数据库的话，也可以安装一下其他相当数据库的一个内容，这两个都是呃，它支持的一个相当数据库。然后的话呢，呃，这个L的话呢，它一共是有六个模块啊，包括我们的一个models这个模型管理，我们可以把不同的一个L IM啊，还有就是这个迁入的一个模型都可以在这个models这一个模块里面去。

翠仪

02:35:25

进行管理，然后P的话，这个其实就很好理解，就是管理我们不同的一个P。那么不同的任务的话，我们可能需要了呃，输入给这个模型不同的一个pops。所以呢，我们可以把不同的pose都这个放到这个P模块里面。圈的话呢，其实就是一个L呃，就是链条，然后它可以把这个IOM和其他组件呢先结合起来，然后整个流程包括我们之前这个做这个销量化搜索的时候，我们呃这个查询的流程不是先把这个问题。去做向量化，然后这个就把这个向量到这个向量数据库里面搜索，然后搜索出来的一个结果，再和整合到我们的这个跟我们原来的问题一起输入到这个大语言模型，最后靠这个大语言模型去输出最后的。

翠仪

02:36:17

结果所以你长串的一个流程我们都可以用一个嗯去啊！

翠仪

02:36:24

管理。然后in的话主要是这个外部的一个数据的一个接口的话，就是这个以前的一个对话的话，是一个比较复杂的东西，它可以去做更多的一个流程管理，那大致上的话就是这。呃，六大块的内容，你如果把这六大块的一个内容理解了，你就可以掌握这个的一个基本的一个使用了。它呃，首先的话，从这个model来看的话呢，它提供了各个模型的一个集成接口，然后的话呢，呃，它其实有三类模型，一个就叫I YY M就是一个普通的大语言模型，然后它输入的是一个P，你要通过经过大语言模型就可以输出一个这个。呃，相应的字符串串的，然后另外一个叫做这个cheap model train model的话，跟这个IOM其实类似的，只是它会有，呃，它直接呢会有一个上下文记忆的关系，它可以把这个聊天列表呢直接去输入进去。

翠仪

02:37:28

然后还有就是一个文本嵌入的一个模型，因为我们去做文本搜索的时候呢，都需要去做文本嵌入，所以它呢也会有一个文本嵌入的一个模型。

翠仪

02:37:39

然后在这里的话呢，我们简单去看一下它的一个使用方案。然后这个。在这里的话，我们使用的话会从这个里面去呃，加载不同的一个模块，那因为呢，它并没有支持这个GLM类的啊，或者是说其他更多的一个呃，就是更本土化一点的这个。

翠仪

02:38:11

语言模型的。所以在这里的话呢，我们是基于它的一个LY类，继承了它的LY呢，去呃复写了一下我们的这个呃GLM的一个模型，然后让它可以去用我们的GLOM去。呃，作为它模型的一块，呃，就是这个GLM它本身的一个呃参数的一个设计，主要是重写的这一块。因为那个QLM它原来的一个输出呢，它不是直接是一个这个呃字符串的形式，呃，这个乱串里面要求模型返回的是字符串，所以的话呢，我们只是把它的一个给它提出来。需要他原先返回，还有一个这个他的一个呃历史的一个信息。

翠仪

02:39:02

然后包括这个模型加载的话就是。一个一个呃，常用的一个方案，那么其他其实就没有什么要改了，然后我们用这个模型的话，就可以初始化我们的一些GLM模型。就实例化，我们的GI模型就这里输入的是我们的这个呃模型的一个选中路径就好了。

翠仪

02:39:48

Ok那我们去给他对话的时候就是，呃，跟普通的一个对话方式一样，我们就是给他说一个文本，然后他返回的也就是一个文本。那在这里的话，它本身是自带了这个上下文的一个记忆关系的，所以就是说，呃，我们可以不需要去考虑我们在一次对话中的一个上下文，呃，的一个管理，然后它也有一个上下文的一个。程度的一个限制。然后第二个的话呢，就就是我们的一个GLM的一个这个L的一个mod。就继承了它的一个类，然后还有就是这个P的一个管理啊，所以就是我们可以把我们所需要的这个P呢，呃，给它放到这个的一个呃。

翠仪

02:40:43

类型里面就比如说呢，我们输入的啊，我们可能想要他去帮我们去搜索某些这个学习某些东西的一个资源介绍，那我们可以定义它的一个input的一个item。嗯，就是这个呃变量呢是叫叫item，然后我们这里呢就是呃把它这个输入给它替换掉就好了。比如说像这样子，我们输入的这个item是拍摄，那我们这个point呢就会自动去更新，变成这个拍摄。

翠仪

02:41:16

比如说我们变成这个。的话呢，这里的这个炮呢，就会根据我们的输入呢，是有一个有所改变，那这样就可以更好的去管理我们的这个不同的一个泡的一个格式。然后有了这个胖，有了这个呃呃大语言模型的话，我们就会构建一个最简单的这个链。

翠仪

02:41:43

啊，这个练的话呢，这个输入的就是我们想要学习这个，比如说某个语言，我们直接输入这个语言。然后这个最后就是得到这个，呃，模型的一个回复，那这就是我们最简单的一个链。我们可以看到它的一个回复的一个结果，就在这里的话呢，我们这个P。呃是等于这个呃，这个是就只有一个P和这个，呃，所以呢，我们去做的一个东西的话，就是相当于我们收入输入了拍，然后他帮我们去做的就是把这个拍。嵌入到这个里面，然后就变成了问这个。哦，我们学习开始的一些资源介绍，然后GLM呢去经过思考呢，得到这些的一个呃回复，然后这就是它的一个呃最简单的流程，其实也相当于我们日常去进行这个聊天的一个流程。

翠仪

02:42:41

那这个是一个？呃，这个具有上下文的就是如果你有兴趣的话，你可以继续就它这个内容再去进行进一步的一个追问或这个问答。那这是这个mod和这个链的一个组合。那这个练的话呢，其实。它除了输入到这个form里面的话呢，呃，它还会去把这个呃可以把多个I YY给它组合起来，然后去呃跟外部数据结合啊等等这些都可以去做到的。很更复杂的应用的话，在这个我们明天去做这个知识图，呃，这个拿机器人的时候在为大家去剪掉，然后这个刚刚说的这个in的话呢，就是一个这个呃外部的一个数据。

翠仪

02:43:38

那这个外部数据的话呢，我们可以用这个呃，的相关的一个模块的去加载这个外部数据，那呢提供了不同的一个这个呃，类型的一个文档加载。那我们可以直接去看他的这个。Data可能是把他的一个data low的啊，就看看对他的。它支持的一个数据，外部数据格式的话呢？是非常多的啊，我们常见的这个什么？TXT啊呃CSV啊excel word啊PDF啊，它都支持。相应的一个接口支持，那更有甚者的话，它还支持一些这个像youtube啊呃哔哩哔哩啊。等等的这些这个呃视频加载器啊，当然这个但是我还没有测试过，因为这个我看了一下，就是它用的是这个哔哩哔哩API的一个拍子。

翠仪

02:44:42

就呃，用的是一个API接口，就获取到这个B站上面某个视频的一个呃信息啊。但如果这个API变了的话，在这个。呃，户那应该是用不了他就户目前是处于一个停根的一个状态的。然后包括一些这个聊天记录啊等等的这些啊，甚至你是上的一个内容给我上的内容，它都可以帮你答取下来，作为它的一个聊天机器人去回答的时候的一个外部知识。那还有就是这个搜索引擎呢也是可以的，就像毕业一样，你在问他的时候他就是在搜索，呃，比如说呃有什么有什么问的呢？可以问问一下这个搜索相关的，比如说。啊，这个一下子没有想到什么问题，就问他那个，随便问他一个。

翠仪

02:45:40

他他，他会去进行这个搜索，因为B一本身是一个搜索引擎，然后他得到一个结。这个回你的这个信息呢，是基于他搜索之后得到的前几名的一个结果，然后综合得到的一个消息。比如说橙橙色的一个呃食物的话，它会找到一些什么样的一个食物，然后可以吃什么，然后就是下面它的一个数据的一个来源。呃，这个用N也是可以做的啊，就这个呃，只要你写好这个搜索引擎的一个API就好，它本身也提供了一个谷歌搜索的一个API。这个啊，赔的太多了。就就就就是这个具体的一个内容，就是这个line它可以做很多。

翠仪

02:46:30

那我们这个待会的话呢，我们只要去做一个这个呃，文本数据的一个加载，所以就可能只关注一些这个PDF啊TST啊word等等的一些资料，然后它也支持这个向量数据库。但是这个销量数据库的话呢，支持的内容呢，确实也挺多的。嗯，就大概是有这些吧，就包括我们之前所讲到的这个QJM他也支持。Open就是向量画风型。嗯，像数据库在这。它支持的这个我们之前所用的，它也可以去做一个本地化的一个持有化的一个，呃，部署，就不一定是用云资源，那你也可以继续去用云资源。然后这个记忆的话，其实就是把它的这个呃，我们的一个对话啊，给给它放起来是一个呃对话保存的一个功能。然后还有一个呃。这个功能的话，其实是这个里面一个很核心的功能，也是它能做很多字的一个功能，它这个的话呢，其实是，呃，把这个P呢会拆解成不同的一个任务，然后呢，根据我们的这个。任务需求调用不同的工具去呃获取到这个呃任务的一个结果，然后再把不同的一个结果呢合并起来，一起呢，用这个再由这个代语言模型合并最后的一个综合结果发送给用户。

翠仪

02:48:16

就比如说。呃，它官方给的药力就是说，呃，比如说我可以问一下今天是天气是多少度吗？然后这个天气度数的平方数是多少？你可以直接这么问他啊，他是可以去给你一个回答回答的。

翠仪

02:48:34

就是它首先第一个任务就是查询，嗯，这个今天多少度还要得到一个结果，然后第二个任务就是这个有度数呢，它的一个这个。

翠仪

02:48:44

啊，平方数，然后就是得到这个结果，再算它的一个平方数，然后再得到最终的结果，然后再发送给用户，那就是他最终不能得到的一个呃，用户。的一个结果。那我们可以给你演示一个样例，就这是那个谷歌搜索的一个呃，API它的一个key啊，这个key大家可以先用，但是可能过几天我就删了，因为它有免费的一个额度，就大家用多了可以用不了。然后它这个engine呢给的一个样力呢，它可以用的一个工具呢，就包括我们的这个，呃，谷歌搜索的一个API的一个提供商，然后还有一个类似的叫做L YY match，就专门去处理一些数学问题的。然后这个输入的还是我们的这个LYO？然后的话把它封装成一个engine engine的话，把这个工具给它放进去，然后我们的这个engine的一个呃类型呢是一个C，就是这个零样本学习，它没有任何的一个学习样本。

翠仪

02:49:52

然后我们会把它的一个呃，详细的内容给它，给它输出出来，那我们就可以去看到了，就是呃，先问这个。呃，哪里的就是它官方的案例，它这个呃某个地方它昨天的一个华氏温度，然后这个华氏温度的00.23的一个释放是多少？然后它就会把这个过程呢，就是整个agent它思考整个LYN思考的一个过程呢，给它显示出来。就是说首先第一步它因为我问的是温度，所以它去，呃，搜索这个问题的一个答案。

翠仪

02:50:34

然后这个呃这个问题的话呢，它可以去获取到是73.9的一个滑适度，然后的话呢，再去算它的一个零点的。三次方的话得到的是109的一个，大家可以去运行一下，就比如说把它的这个。呃，但是因为它这个工具就上面用到的就算数的工具I will match它原生的一个模型可能是这个英文的。我试了一下中文的这个不太行，它思考的不太行。就通过这样的一个呃安准的一个管理的话，我们可以实现更多的一个任务。然后就是内存的一些管理啊，这个就没什么好说的，就是它的一个历史的一个数据。然后的话刚刚所说到的这个呃，我们的一个test的就是这个数据外部数据的一个加载的话，就考虑到我们之前的哈，比如说上周所用到内科数据，它可能是一个TST，那我们可以用一个。

翠仪

02:51:41

它的去给它去加载，然后的话它整个流程其实我们之前所说的把这个呃文本去进行这个分块啊，读入进来啊，是首先读入，然后去进过这个分块，然后再把它这个做向量化存到这个数据库。下到数据库中都可以用N train的几个这个代码去完成。就比如说像这里它有一个这个加载器去low的啊，我们去可以针对不同的一些格式的数据，有不同的一个low的，比如说TXT的话是一个test ladder。

翠仪

02:52:15

我们可以把它加载进来，获取它的一个数据的内容。然后的话呢，我们需要把它去切分这个文本分块，那我们可以用这个字符串的一个txt的，就，就，就按字符来分，比如说它每一块可能是500个字，然后块块之间呢是没有。

翠仪

02:52:32

重复的，然后我们就可以得到这个分块之后的一个结果，然后的话再把它这个做向量化，那我们可以直接用这个hanging face in building这个呃，接口去把它的这个我们之前。

翠仪

02:52:50

啊，所下载好的专门用于这个呃医疗数据上的一个呃。数据啊，这个这个这个相当化的一个模型呢，给它加载进来，直接构建成一个imbalance的一个模型。然后的话呢，我们创建这个数据的话，也用这个本地数据啊，这里用的一个模式呢，是这个存放到内存里面。然后呃，有了这个数据库的话，它就会自这个数据创建的时候，就自动的去根据我们刚刚分化的数据的，呃，和我们的embon的这个函数的去创建这个数据。最终的话呢，把它放到一个这。呃，QA的一个问答里面呢，我们就可以直接得到一个问答机器人呢，就这样基于外部向上搜索的一个问答机器人。呃，大概是这样的一个流程，那这个样例的话还是上一周的一个数据呃。

翠仪

02:53:50

就呃，我这里写了一个，就是稍微有点。这个什么的用东西就大家可以看一下，就其实拆分下来的话还是跟上周一样，呃去把需要把这种呃基于本地文档的。这种呃，基于向量搜索的一个呃问答机器人它要建起来的话还是两步，第一步呢是这个呃数据的一个呃拆分和向量化搜索。

翠仪

02:54:26

然后整个流程的话大概是这样的，我这里呢呃定义了一个分句的一个函数。这个分句函数呢？呃，是因为我觉得可能你单纯的按这个字数去进行这个切分的话，可能是有点不科学啊，我们更多的希望它是按这个句子来分，那我们就是先把它的句子来分，然后去把，呃。呃，定义了这个，比如说它输入一段文本，它这个文本，这段文本它有着一个句子的一个数量，然后我这个后续的话再去做这个分化的时候呢，可以基于十个句子啊，或者是五个句子。它作为一块，然后它们上下文呢，保持一些上下文之间的联系，那可以把这个上一个块最后一个句子放到下一个句和句块里面，就有一个重复的，就这样的一个句子保持它特别比较好的一个上下文。啊，那如果你想保持好一点的话，你这个参数会设置大一些。然后呢也写了一个data loader的一个呃函数，主要是针对了不同的一个数据原模需要加呃，用不同的一个loader去在这个把这个数据给加来进来，比如说像这个呃。

翠仪

02:55:41

PDF啊dos啊这个HTML J CSP就是我能想到的，呃可能是支持这些，那如果他不支持的话，可能就是啊没有东西去返回的。那整个流程还是跟之前的一样，我们首先呢，呃，比如说我有一个文件哈，在这个data里面，我现在有一个这个呃PDF还有一个what啊，那但是我是这个之前写的时候可能只放了一个PDF，然后把它这个呃获取到这个文件列表。

翠仪

02:56:13

然后的话呢，啊也初始化我们的这个呃文件，呃，这个文件化的一个文本块的一个分割器，然后初始化我们的这个呃销量化的一个变量，然后便利这个呃数据及呃这个data里面的。这个数据集大家可以在测试的时候呢，用自己的一些数据集去进行这个测试。

翠仪

02:56:36

然后呢就是把这个加载进来，汇集到它里面文档内容，然后再去进行这个分块分块之后呢，写到这个数据库，那这个数据库的话呢，呃，因为后续呢还需要调用，所以呢做了一个本地化的图。这个设定它可以直接写到这个本地化的这个路径上面，然后储存的一个就是叫做买的。然后就可以把这里我data的文件夹里面所有的一个呃。包含这些后缀的，当然你有些可能就是包含这些后缀，我这个加载还是有失败的，那这个可能是有忽略。那大概是这样的一个数据，那之前呃做完之后的话，我们可以请一个这个呃QA的一个服务，然后的话我也基于这个呃。

翠仪

02:57:27

我去改了一个有点类似于清华的那个，但是我把一些这个没有用的东西呢，给它删掉，就加了一个上下文的一个对话，大家可以先看一下效果，就是可能这个时间。有点这个不够。还有那些。那还是刚刚的那个链接？就就为侧边栏的那些东西，就是暂时是不在我的一个模型输入里面的。呃，所以我就呃没有输入进去，然后这个呃，我之前测试的一个数据就是存到相当数据库里面的数据呢是什么？是一个PDF。

翠仪

02:58:34

呃，就是中大的一个科研经会的一个管理的一个PDF，就实在是想不到有什么好玩的一个数据集，呃，如果大家有什么建议的话，也可以发我一下，就明天这个放上去，大家一起去体验一下，然后。

翠仪

02:58:49

呃你有刑法相关的数据吗？啊，有是发几个啊，就就不，不知道怎么找，就有些时候备课的时候背到这个头脑花，呃这个有点有点晕啊，就不知道写什么，就可以问一些科研经费管理的一些相关内容。比如说呃问一些他。那个。怎么申请。申请流程是什么？他的话，然后他现在是做一个呃数据的一个加载。那它，它这个脚本就是我有问题，你问问题呢，它在加载这个模型。哦，那个不打？哎，我是跑什么把他那个选择全战嘛呢？我不打这个显存码的。哎，我是跑了啥，等等等他那个降下来我再重启一下。不对，还有14G的？

翠仪

03:00:34

嗯。是之前我有模型没有释放显存吗？也没有。哦，这个哦，我这个line上面那个加载了模型。就是显存不够的话就容易出现这种问题。

翠仪

03:01:16

然后整个代码流程的话，大家呃，为了便于大家去观看的话，也可以去看一下这个toy test的一个robot。从它整个代码流程的话，其实是跟之前差不多的，就展示了一些这个我去做数据化的时候就读入的这个刚刚我这的这个本地化的一个相当数据库，然后的话呢，我们可以在这个相当数据。

翠仪

03:02:12

库里面去做一些相关性的一个搜索，然后去做一些查询，然后上下文的话，它也会有一些这个它相关的内容，比如说它找到的一些相关的一个内容。呃，知识。我这里还有个报错。最后输出的一个报错。大概是这样的一个过程的一个内容。这是他的一个回复。呃，因为时间关系的话，这部分的话各个就是TTOM嘛。那那个。应该等着上场，一般的说法是用上周的那个test。哦，今天可以啊对。呃，就关于最后这一块的话，大家还有什么问题吗？就后呃，明天的话再再再可能再把这个丰富一些。就因为今天确实时间也差不多了，看一下大家有什么问题想要提问的。

王波

03:03:30

喂嗯，你好。

翠仪

03:03:31

对，就后面那个？他当时就还是之前那个一样的，就等于是把上次的那个实现哪一次，嗯，是用nation实现的一次。嗯，你好，王波是吗？

王波

03:03:42

啊对，就那个您这最后这个代码用调大模型的是在哪哪一句啊，代码？

翠仪

03:03:45

你说这个服务器的这个版本吗？

王波

03:03:53

最后。对对对，就你刚才演示这个是哪一句代码是掉大模型？

翠仪

03:03:59

在这里啊，就是get model的时候去调实例化的一个数据的时候。这里。

王波

03:04:05

呃，我我做还有个问题，就接着接着刚才上一次问的问题就是说你在指令微调的时候，假如嗯，我我有我的专业的指令微调，然后再加上呃就是一个公共的指令微调那。

王波

03:04:24

这这这两个只能微调的数据，我到时候是。直接就合并成一个阶层文件吗？还是怎么弄啊？

翠仪

03:04:31

哦，对，直接合并成一个节省文件去进行微调就好了。

王波

03:04:36

哦，但是你那个专业里面有一些指令啊，那些指令和我的。

王波

03:04:41

呃，就是指定微调的格式是完全一样的吗？如果格式不一样或怎么办？

翠仪

03:04:44

呃，其实你的那个指令的一个数据集，无非就是一个一步一个offer嘛，就一个输入，一个输出，就无论你包含哪些指令，你的这个都是整合成一个输入。

翠仪

03:05:00

一个输出的呀！

王波

03:05:01

是对，但我看你那里面有一个instruct什么什么？

王波

03:05:05

指令的一个。

翠仪

03:05:06

嗯，就最后我是合并成了，就把它的一个职业和它的一个输入的文本都合并起来了，然后去用这个合并之后的去做这个微调的输入的。

王波

03:05:14

嗯嗯，我明白，就是说设计这个指令专业指令微调的时候就要多那么一小块的。东西是吧。多你一个指令的。

翠仪

03:05:29

哦，对，就是在那个开始之前可能就是明确一下我们这个任务。

王波

03:05:35

好，明白好，谢谢！

田志军

03:05:38

哎，何老师。

翠仪

03:05:39

嗯，你说。

田志军

03:05:40

呃，你这个有，如果他你刚才说那六个步骤当中有一个pro那个那个嘛。那个。呃pro那个初始化的那些模板？呃，是怎么来的？

翠仪

03:05:53

你说哪个初始化的模板？

田志军

03:05:55

你你刚才做了那个这个模型不是有六个步骤吗？其中有一个第三个吧，就是那第二个吧，就是那个pro那个嘛。

翠仪

03:05:57

这个模板肯定是自己编的呀！

田志军

03:06:07

对，但是你要是自己编的话，呃，你能够怎么能够让琼静说我，我因为你。

田志军

03:06:14

你你用户回答的那个问题可能是开放的。你能穷我们能够穷进出或者有什么方法能穷你出这个模板的它的那个类别吗？

翠仪

03:06:24

你你你想用一个模板去覆盖所有的那个类型，或者是有限个模板去覆盖所有的类型，其实是。呃，好像这个不太呃不太能够，就一般情况下的话呢，比如说像这个向上搜索的时候，我们用的模板是这个，你可以参考一下。

翠仪

03:06:50

这个txt里面？这个touch里面机遇的模板就是使用下面的一个上下文和聊天记录啊，去进行这个呃，问题的一个回答，然后呃，类似于这样的一个模板，就是你的问题肯定是包含在你的模板里面的。然后你使用什么样的一个数据去回答这个问题的话，那这个就是要你的模板去设计。

田志军

03:07:15

呃，我明白就是呃，首先是我们呃，先要把你这个输入的这个一段话，然后套上那个普通模板，然后再往后面走嘛，我的意思就是这个。

田志军

03:07:26

普通这个模板？是我们刚才说的是我们自己要是手动来去录入的，然后我的问题就是我们是一个开放的，录入的这个一个开放的这个领域，我怎么能够呃，设计比较好的这个模板让他啊往后面来去进行走嘛，我是这个意思。

翠仪

03:07:45

什么是另一个比较好的往后面这种，这个就是当你面对的是所有的一个客户的时候，他的这个。输入本身就不可控的。就你的他不就是不可能让每一个人都可以得到他满意的答案的。也就这个呃，就你只能是针对你的这个领域上面去做一些修改，就有一些时候你甚至不用碰它，为什么你就要带语言模型回答什么就好了呀？

田志军

03:08:17

那如果用大眼膜用回答那个这个pro还有用吗？

翠仪

03:08:22

这个是呃怎么说呢？你可以去更加多的去看一下方工程，呃，这个胖主要是比如说你普通聊天的时候，我在呃跟这个呃闲聊的时候，你可能是不需要什么碰，大家反正就是随便的。去呃说嘛，当你想用这个带语言模型去做一个指定的一些指任务的时候，那你这时候你的P就非常重要了，就比如说刚刚所写的这个呃去呃，从已知关系里面去抽取。

翠仪

03:08:55

这个三元组，那这是呃，这这本身就是一个P这上面它的一个指定也有我的一个输入嘛。那这是一个指定的一个任务场景的，你你本身是可能想做的，你直接让它这个呃，从这句说一句话，然后说从这句话里面去搜，呃，去提取这个呃关系列表的话，这这就可能就是它没有办法很好的去。回答你这个问题。

田志军

03:09:26

嗯，我那我再问一个就是就是这个呃，如果是我们自己，然后来去部署模型，自己做这这个东西的话，那么这里面还有一个可能是一个意图识别。这个意图识别和这个prom有关系吗？或者说它俩是一个什么样的关系，或者说没关系。

翠仪

03:09:46

呃，意图识别的话，其实呃它本身就可以用一个P，就比如说你在它这个在它上面，呃，在我书的问题前去加了一个指令，请识别以下问题的一个这个所属于。哪一个意图要给它一个意图列表，然后再输入我们的问题，那它就可以去做成一个这个意图识别，然后我们会根据它输出的一个内容，再去进行下一步的一个动作。

田志军

03:10:21

好的，我再想想吧！

翠仪

03:10:24

嗯嗯嗯，好行！

翠仪

03:10:36

哦喂，你好听得到。

王波

03:10:37

诶，我还有个问题。就是你刚才说那个能够访问那个？外部的一些网站是吧？就是。

翠仪

03:10:45

哦，对。

王波

03:10:46

那些网站的网址我可以随意增加嘛？还是说就是只能访问那些啊？

翠仪

03:10:52

呃，你说的是单串里面的那个加载吗？

翠仪

03:10:58

呃，这个你可以增加，就是这就是相当于你回答的时候的一个，就是相当于你向量知识库的一个数据来源，你可以在这个导数据的时候去呃，写好，然后或者是在后续的一。

翠仪

03:11:16

就是后续的就再续去增加，然后去修改我们的一个相当数据库就好了。

王波

03:11:23

嗯，不是不是就是刚才你那个冷颤是不是能访问那个谷歌呀，去搜索还能访问？

翠仪

03:11:29

哦，你这个是搜索的，搜索的是搜索的一个API URL是URL。

王波

03:11:33

对对。

王波

03:11:34

就就那些，我能够随意增加那什么网址？

翠仪

03:11:38

随意增加什么？

王波

03:11:40

就是比如类似于谷歌的，百度的，还有其他的一些网址，我能不能随意增加这些东西？

翠仪

03:11:47

呃，这种的话你可能要自己封装一个，就是它默认现在所提供的一个搜索引擎的话，还是这个谷歌就是一个第三方公司所提供的一个API，那如果你自己想要实现去，比如说你要去做百度搜索或者其他搜索引。

翠仪

03:12:03

你的搜索的话，你要自己封装好这一块，就自己就自定义一个这个搜索以及的一个搜索。

王波

03:12:07

啊，就它就就是它原始的是没有哈。

翠仪

03:12:14

哦，没有。

王波

03:12:15

哦，还有一个问题就是说。

王波

03:12:18

呃，类似的就是说我访问自己的数据库什么的也要自己封装是吗？

翠仪

03:12:24

访问自己的一个数据库的话，呃数据库加载的话，它是有的，就看一下你是什么数据库，比如说呃。

翠仪

03:12:34

你看这个。

翠仪

03:12:40

他他他我还有这个文件结构是在哪？

石鹏程

03:12:42

<噪声><噪声>。

翠仪

03:12:45

那个可能是里面有一个这个数据库的一个可能它甚至可以去做这个数据库的一个查询的。

翠仪

03:13:11

嗯，还有其他同学要提问吗？

许涛

03:13:15

何老师。那个。现就现现在那个网上有没有现成的那个知识图谱的那种库资源？

翠仪

03:13:24

呃，开源的知识图谱是有的。

许涛

03:13:28

就就像这个这个大这种大语言模型，这种直接就是现成训练好的预训练模型，就是就是这种知识图谱，就是呃那种通用型的知识图谱模型有没有吧？

翠仪

03:13:40

有这个open KG你可以去看一下，上面它有一些这个知识图谱的一个资源，就这些数据。那这些数据的话有一些比较旧的话，它可能链接已经这个失效了。

翠仪

03:13:58

这个叫做open KG？

许涛

03:14:02

它这上面是？啊，也是分各种类目的是吧，也不是说就那一个库是吗？

翠仪

03:14:09

它，它其实就是一个这个数据整合的一个整理的一个界面，就它上面整合了很多这个知识图谱相关的一个内容，比如说这上面它有一个这个百科知识的，那它还会有这个项链的链接你。转跳过去。就可以下载到他这个百科知识。然后不同的一个知识图谱的话，它可能有不同的一个呈现的一个方式吧。

许涛

03:14:30

嗯，就是说加载的时候还得需要不同的，比如支持。那个。

翠仪

03:14:41

它只是相当于给了你一个这个数据源，这个三元组合，然后你要还是要自己导入到自己的数据呃，图数据库里面，毕竟数据库是你自己的呀。

许涛

03:14:51

啊，就比如说他自己的那个是你就你NU CG什么就那些。然后他提供的这些都是标准的那种三元组的格式是吧？

翠仪

03:15:00

呃，这个我就不能确保了，因为它只是整合起来，就是大家共享出来的，嗯，呃，没有说一定要求它是一个三元组的一个格式。

许涛

03:15:19

然后刚才说的那个？病搜索里边他那个那个问答的那个。他不是有一个搜索的过程嘛，就比方说我问了一个问题，然后他给了一个。答案，然后能能大概看出它这个答案，它是是是它这个搜索在网上互联网上搜索得出来的一个结果还是。通过这个模型给出来的结果。

翠仪

03:15:43

啊，你说的是哪个搜索就是这个？

许涛

03:15:47

刚才你不是在那个病死，对对对，就就就这里边？

翠仪

03:15:51

这个这个结果的话，是那个模型给出来的一个综合结果，就相当于他把这几个他收到的这几个网站上面所有的内容都综合起来了，然后给出了一个总结性的一个结果。

许涛

03:16:05

是吧，你是说他这个他搜索的是说已经早就搜索好了，不是说你刚问他他，他炫炫搜索不是一？

翠仪

03:16:11

是他一问你，你问他，他就去搜索，然后搜索出来那个结果呢就输给大模型，然后大模型呢在这些结果里面整合出来一个答案去回答你。

许涛

03:16:25

啊，先去搜索，搜索完了，然后处理处理完了给出结果。

翠仪

03:16:26

对呀。

许涛

03:16:30

但它它这个过程会比较慢呀，这样的话。我我我是完全不。

翠仪

03:16:33

呃，确实是有点慢。你可以试一下这个。因为毕竟它这个也是那个微软的产品，但就是用的那个呃，GPT的一个这个产生的，它生成模型的一个速度，你可以去看一下。就是这这个速度，但是我不不知道是不是因为跟那个呃这个VPN是有关系，因为目前中国区呢是没有提供这个聊天功能的。啊，这个国外才有。所以就是你们要用的话，你可以去下载一个这个呃。我去去去摆一下，找一个呃，登录一下那个闭音搜索，然后在上面去修改一下你的这个呃地区，比如说改成香港，它就能看到这个聊天界面，不然的话你只能看到搜索界面。

许涛

03:17:28

但是然后比如说像哦像那个。

许涛

03:17:34

这样的模型其实。我就是他就是一个私有部署，然后我给他断网以后，反正他就是就纯自己模型，它给出的这个结果应该是这样的是吧？就它不需要再再像并这样可以再再去连那个互联网，知道吧。

翠仪

03:17:45

就就一般情况下它是不联不联网的。就无论是哪个模型。就只只只是你想让它连互联网，你想让它的一个结果更加精准一些，或者是实时性更好一些，你可以去加一个呃搜索这样的一个步骤，然后再让它继续搜索的得到的结果再去进行。这个回答。

许涛

03:18:14

一般来说应该可以理解为是它这个模型给出的综合这个结果应该还是好一些的，比如说我人工去搜一下的话，它肯定也也会有一些结果，但那个可能就就。得需要自己筛选什么的可能就不太好了是吧？

翠仪

03:18:30

呃，就是因为这个它这个带语言模型就是帮帮你把这个搜索得到的一个结果总结。

翠仪

03:18:39

总结了一下。

翠仪

03:18:49

它本身也有一个总结的一个模块，但是时间关系我们明天再说吧，就是它可以比如说你上传一个比较长的一个PDF或者是这个文档，然后你可以让他给你概述一下这篇文档里面讲的什么内容。

翠仪

03:19:04

这也是能做的。

许涛

03:19:06

啊，那他这意思是说这个是不是来自于知乎的？我看他这个意思是不是他推荐的一个链接是吧，这应该是。

翠仪

03:19:12

啊，就是它的这个参考的数据源是来自于知乎的这个链接的。嗯，他可能也有参考，其他的主要是这个一根二。

许涛

03:19:21

70度。这都是来自指挥这几个？

翠仪

03:19:26

但他厕所的一个损位可能就是这个吧。因为我问他的是这个。他搜索得到的一个橙色食品的好处，第一个参考的链接可能就是知乎的。

石鹏程

03:19:47

哎，何老师能听到吗？我有个问题想问一下，就是说我把一些数据金量化之后，比如说人员的信息。

翠仪

03:19:50

哦，听得到你说。

石鹏程

03:19:58

人员信息里边可能包含一些基本信息，再加一些手机号。身份证号我通过姓名加20号去检索这个人的信息的时候可以检索出来。

石鹏程

03:20:10

就是下单化搜索出来，但是我只是通过身份证号的话，就查不出这个人的信息来，一般或者他回答我的一些是错误的信息，这个有什么，这是什么原因造成的？

翠仪

03:20:25

啊，其实像你这种的话，就是它本身的信息，如果它本身比较结构化的话，我是不太建议你去做这个相当化搜索，或者是说，呃，在你现代化的时候去考虑一下。

翠仪

03:20:42

是怎么去合理的去向量化，比如说像身份证号这种呃，一长串的数据，你去做这个向量化，其实它得到的这个呃email的一个向量其实是没有任何意义的，是吧？

翠仪

03:20:56

就这个数字，就就就比如说你差一位，它很接近，但是也没有意义，因为它本质上就是两个不同的人，但是你有很有可能就收到一个比较接近的一个身份证号。

翠仪

03:21:09

但但不够精确，其实像这种比较精确的或者是结构化的数据的话呢，我更建议是放到这个呃关系型数据库里面来，根据这个呃数据的一个属性去进行这个查询会更好一些。

翠仪

03:21:25

或者是你把它放到知识图谱里面，做成一个这个呃，人的这个属性啊，也是可以的。

翠仪

03:21:35

就这种结构化的知识的话就好，就放数据库会比较好一些。

石鹏程

03:21:40

嗯，再就是一个问题，就是说把数据进行向量化，就我我我简单试一下，像就是说我入了，比如说大约是二十，二十多万的数据之后。他好像就之后的话应该是在20左右，这个是一种正常现象是吧？

翠仪

03:22:01

呃，正常的。

石鹏程

03:22:03

如果就像如果这个数据达到达到，假如说是达到一亿之后，它开盘存储量可能达到了77甚至十T的这种样子，这样的话就就不适合做一个搜索了吧。

石鹏程

03:22:18

像两块钱。

翠仪

03:22:20

呃，其实你数据量这么大的话，你可能就是要在这个本身这个向量化数据库的一个选择上，你就要更好的去考虑性能更好的一个数据库。

翠仪

03:22:32

就提高他的一个，这个我在去做相关知识的一个相当化厕所的时候。呃，但你就就就这么大量的话，确实，呃，你在搜索的一个策略上面，可能还需要根据你的业务场景去进一步的一个细化，可能就是搜索的时候不是通过全量搜索，或者是通过一些什么限定的一个条件。先限制一下它的一个搜索范围，然后再去进行这个相关知识的一个搜索，然后这个搜索结果再去放到这个代言模型里面，最终得到最后的一个结果。

石鹏程

03:22:59

啊嗯，那何老师你到时候明天可以就讲一下他的一些索引，就是说可以简单，到时候介绍一下索引索引的一些信息嘛，就是说他的一些。像的话，创建的时候那些索引。可以到处去讲一下。

翠仪

03:23:28

呃，就销量化数据库的话，这个其实它本身只是一个工具，然后它这个具体的理论的话，可能就是跟我们这个课程它本身的一个主题的关系并不是那么大，而且这个时间可能也有限，可能你。

翠仪

03:23:46

讲不了多少，这个可以是在后续我们的这个还有后续一系列课程里面啊，其中一个课程计划的话，主要就是讲这个向量化数据库的，到时候你可以关注一下。

石鹏程

03:23:47

有问题就是说我们在的时候，比如说我们做一个的一个请求请求的时候，他就是说可能一个问题。

石鹏程

03:24:12

请求三个问题吧，他回答时间都会进行延长。这这是应该是他他。耗费的资源也会。就是这个意思就并行的时候。呃，我们请求三进行三个问题，回答的话，可能每个问题都需要两分钟，但如果我们一个一个问题问的话，他就一分钟就能回答出这个问题来，这样的话就是说我们后期的话还想实现一个变形的一个操作，有什么优化方案嘛。

翠仪

03:24:42

呃，没有太听明白。

石鹏程

03:24:45

呃，就是说你。

石鹏程

03:24:47

现在是一个串行的，比如说串行。一个一个请求的求问。可能靠一个一分钟就回答出来了。

石鹏程

03:24:55

但是我们尝试就是病情的去请求，就是说三个请求一起去问这个问不同的问题。他可能就会每个问题都耗费两分钟。他就是说等待时间就会变长。但是呃，但是我们还需要这个定型的功能，想想问一下有没有什么优化的方案，那他就说。变形之后，他回答问题的速度会增加快一点。

翠仪

03:25:20

嗯，并行呃，并行的问题的话会慢吗？

石鹏程

03:25:30

对对对。就是说一个一个问题，同一个问题，我问的话。

石鹏程

03:25:37

他可能一分钟回答出来我我病情的问三个问题，那个问题的话。

翠仪

03:25:43

就是一次性问他三个问题吗？

石鹏程

03:25:44

对对，就是并发并发请求。他呃同一个问题。

翠仪

03:25:50

并发请求并发请求证，他有你部里面处理的逻辑还是串行的呀？

翠仪

03:25:57

只是你的请求是并发的，但是他会排队负责，但本质上还是串行的呀！

石鹏程

03:26:02

本质还是穿行的那个我们如果想做到并行的话就有什么方案吗？

翠仪

03:26:10

这行的话，你就要多付几套这个模型它才能有变形的可能，不然你一套一个模型一次他肯定是只能回一个问题啊，他处理逻辑是。

石鹏程

03:26:22

那这样的话，他不就是可能一些模型可不可以就说一个模型加载之后。嗯，他一个模型在现在占正常的话占12G左右嘛。只回答一个是不是有点浪费，这样的话？

翠仪

03:26:40

啊？什么意思？

石鹏程

03:26:40

有没有一种方案，就是说让他同时去回答并行的去回答嗯问题嘛！

翠仪

03:26:49

主要它不能做变形的原因是因为它显存，他我在做推断的时候，我整个模型的一个显存都是要的，那我输入的这个问题啊，他要做这个啊，首先放到显存里面，然后去跟这个做模型推导整个模型的一个。

翠仪

03:27:07

全都是需要的，那你这个模型的一个在计算推导的时候，你这个显程呃，相关的这个是不能动的，那它不可能它它内部的流程就是要这样，这个单线走的呀，你同事输入进去它也只是排队，就是从这算一遍再算一。就是这一块，你只要是一个模型，占据的是这一块的一个显示资源的话，那它推断的时候，那肯定都是这个呃，单一的这个串行的呀。

石鹏程

03:27:29

啊，那那如果要如果一定要实现病情的话，就是多补几套服务是吧？

翠仪

03:27:47

啊，对，就是呃，你需要把它布到不同的一个呃显存资源上面，不然的话它就会打架，你这个你一个再算的时候另一个又进来了，那不就乱套了吗？

石鹏程

03:27:54

啊，可不可以这样，就是说我们就是说可能假如说一个80G的..存，我们可以在80....同一台服务器上，我们可以不装个那个..。

翠仪

03:28:16

嗯嗯，没听到最后一句。

石鹏程

03:28:19

就是假如这这台服务器它有80G的鞋。

翠仪

03:28:19

就是80岁的？

石鹏程

03:28:24

我们可以补两个或者三个六B是吧？

翠仪

03:28:29

哦，可以呀。

石鹏程

03:28:31

啊，其实这样就没什么影响了是吧？好的好的，那我的问题问完了，谢谢何老师！喂，能听到吗？

石鹏程

03:28:42

哦，我的问题好的好的，谢谢何老师！

翠仪

03:28:42

哦，听得到。

许涛

03:28:49

何老师，刚才我有个问问题忘了问了，就是那个。呃，那个知识图谱？呃，就是咱们只要是牵扯到这样的项目的话，是一定是是得从零开始弄一个知识图谱的一个结构嘛。

翠仪

03:28:58

嗯，真没没不好意思，没听到这个什么，从零开始用知识图谱的结构，你说的是？

许涛

03:29:11

就是就是咱们比如说开始一个项目，或者做一个什么什么，比如说我做一个项目吧，然后这个项目需要一个知识图谱的一个东西，然后这个这这个这个知识图谱，它这个数据库每每次都得需要从零开始弄一个知识图谱的数据库。

翠仪

03:29:12

嗯。哦，不是啊，不是不是，那肯定不是啊，就是你已经见过的这个你就不用管了。你后续就是跟你数据库管理一样，它本身就是一个数据库，你增删改查都是可以的，你可以增量的呀！

许涛

03:29:41

所以我就想问问的就是比如说比如说补全吧，或者是什么就是呃。呃，是不是就是可以像这个大模型微调这样，你刚才不是说有那个什么open KG上？

许涛

03:29:53

那些那些知识图谱把它虽然比较旧了，但是也可以通过补权或者什么样的措施，然后这个让让让这个大元模型去给他做一些补全，成为一个自己可以用的一个新的一个图谱的一个知识图谱的一个结构啊。

翠仪

03:30:09

呃，理论上是可以的啊，就是用这个代表模型去帮助我们去补全这个图谱的一个关系。

许涛

03:30:18

就虽然它比较旧了嘛，但是说我通过大语言模型对它进行做一些微调，做一些补全，做一些优化什么的，让它成为一个比较新的一个一个这个一个知识图谱的结构，这样可行吗？这个。

翠仪

03:30:33

呃，这个要看一下实测的一个效果，就呃，现在的话就知识图谱啊，就是涉及到一些比较精细的，或者是说比较冷门的一些领域，它的一些知识抽取或者是这个。

翠仪

03:30:48

股权啊等等的一些任务，其实大家会发现就是呃，准确率来说的话，肯定是这种监督学习，经过这个追加训练的这个准确率会高一些，就是它有一个呃。门槛嘛，就要有标注数据去训练数据呃模型。

许涛

03:31:08

啊，您说的是就就说。

翠仪

03:31:09

就当都可以去，就是去抽取，去补全，去提取这些关系，但是的话它的一个呃准确度跟这个有监督学习比起来还是会有一些差距的。

许涛

03:31:23

你说有监督学习，就是自己去找那些语料，尽量找的比较多，然后自己去去抽取里边那些关系实体，然后这么整合更好一些是吧？

翠仪

03:31:34

就是自己标注这个或者是呃李勇，我觉得这就是一般的话有一些比较呃专业的领域的话，可能要自己标注数据。

许涛

03:31:47

然后后边慢慢往上再再往里追加是吧，有新的语料之后。

翠仪

03:31:54

嗯，对呀。

许涛

03:31:57

行，好，谢老师！

翠仪

03:32:04

Ok还有同学提问吗？没有的话我们就下课了。哦ok那我们今天的课就先到这里了，我们明天再见吧！

王蓓

03:32:22

好的，同学们就下课回去休息吧！